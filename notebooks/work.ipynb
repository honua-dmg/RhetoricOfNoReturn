{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "701d8bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting requests\n",
      "  Using cached requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests)\n",
      "  Using cached charset_normalizer-3.4.2-cp311-cp311-macosx_10_9_universal2.whl.metadata (35 kB)\n",
      "Collecting idna<4,>=2.5 (from requests)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests)\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests)\n",
      "  Using cached certifi-2025.6.15-py3-none-any.whl.metadata (2.4 kB)\n",
      "Using cached requests-2.32.4-py3-none-any.whl (64 kB)\n",
      "Using cached charset_normalizer-3.4.2-cp311-cp311-macosx_10_9_universal2.whl (198 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Using cached certifi-2025.6.15-py3-none-any.whl (157 kB)\n",
      "Installing collected packages: urllib3, idna, charset_normalizer, certifi, requests\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5/5\u001b[0m [requests]\n",
      "\u001b[1A\u001b[2KSuccessfully installed certifi-2025.6.15 charset_normalizer-3.4.2 idna-3.10 requests-2.32.4 urllib3-2.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ea97fca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Event_ID</th>\n",
       "      <th>Event_Name</th>\n",
       "      <th>Event_Date</th>\n",
       "      <th>Outcome</th>\n",
       "      <th>Primary_Type</th>\n",
       "      <th>Secondary_Type</th>\n",
       "      <th>Region</th>\n",
       "      <th>Country_1</th>\n",
       "      <th>Country_2</th>\n",
       "      <th>External_Actors</th>\n",
       "      <th>Key_Individuals</th>\n",
       "      <th>Key_Groups_Entities</th>\n",
       "      <th>Date_Justification</th>\n",
       "      <th>Search_Terms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EUR_2022_UKRAINE_CONFLICT</td>\n",
       "      <td>Full-Scale Invasion of Ukraine</td>\n",
       "      <td>2022-02-24</td>\n",
       "      <td>Conflict</td>\n",
       "      <td>Invasion</td>\n",
       "      <td>Interstate War</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Ukraine</td>\n",
       "      <td>Russia</td>\n",
       "      <td>Belarus,Chinese Hackers,International Criminal...</td>\n",
       "      <td>Putin,Zelenskyy,Biden,Alexander Bortnikov,Niko...</td>\n",
       "      <td>Kremlin,NATO,Russian Army,Ukrainian Army,Donet...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ukraine invasion,Russia special military opera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MEA_2023_GAZA_CONFLICT</td>\n",
       "      <td>Hamas Attack on Israel</td>\n",
       "      <td>2023-10-07</td>\n",
       "      <td>Conflict</td>\n",
       "      <td>Cross-border Attack</td>\n",
       "      <td>Asymmetric War</td>\n",
       "      <td>Middle East</td>\n",
       "      <td>Israel</td>\n",
       "      <td>Palestine</td>\n",
       "      <td>Iran,IDF,Gaza,Islamic Jihad</td>\n",
       "      <td>Netanyahu,Sinwar,Mohammed Deif</td>\n",
       "      <td>Hamas,Israel Defense Forces,Al-Qassam Brigades...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hamas attack,Iron Swords,Gaza invasion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFR_2020_TIGRAY_CONFLICT</td>\n",
       "      <td>Tigray War Start</td>\n",
       "      <td>2020-11-04</td>\n",
       "      <td>Conflict</td>\n",
       "      <td>Civil War</td>\n",
       "      <td>Intervention</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Ethiopia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eritrea,militas from Amhara and Afar</td>\n",
       "      <td>Abiy Ahmed,Debretsion Gebremichael,Getachew Re...</td>\n",
       "      <td>Tigray,TDF,ENDF,Eritrean Defence Forces,TPLF,IRAT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tigray war,Ethiopia conflict,Abiy Ahmed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFR_2011_LIBYA_CONFLICT</td>\n",
       "      <td>Libyan Civil War Start</td>\n",
       "      <td>2011-02-15</td>\n",
       "      <td>Conflict</td>\n",
       "      <td>Civil War</td>\n",
       "      <td>Foreign Intervention</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Libya</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NATO,Turkey,UAE,Egypt,France,Wagner Group</td>\n",
       "      <td>Gaddafi,Mustafa Abdul Jalil,Khalifa Haftar,Fay...</td>\n",
       "      <td>National Transitional Council,NTC,UNSC Resolut...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Libya civil war,Gaddafi speech,Benghazi uprising</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EUR_2008_GEORGIA_CONFLICT</td>\n",
       "      <td>Russo-Georgian War</td>\n",
       "      <td>2008-08-07</td>\n",
       "      <td>Conflict</td>\n",
       "      <td>Invasion</td>\n",
       "      <td>Interstate War</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>Russia</td>\n",
       "      <td>USA,NATO,France,Separatist authorities and arm...</td>\n",
       "      <td>Saakashvili,Medvedev,Putin,Borisov,Nicolas Sar...</td>\n",
       "      <td>South Ossetia,Abkhazia,Georgian Armed forces,R...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Russo-Georgian war,South Ossetia conflict</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MEA_2015_YEMEN_CONFLICT</td>\n",
       "      <td>Saudi-led Intervention in Yemen</td>\n",
       "      <td>2015-03-26</td>\n",
       "      <td>Conflict</td>\n",
       "      <td>Intervention</td>\n",
       "      <td>Proxy War</td>\n",
       "      <td>Middle East</td>\n",
       "      <td>Yemen</td>\n",
       "      <td>Saudi Arabia</td>\n",
       "      <td>United Arab Emirates, Egypt, Jordan, Morocco, ...</td>\n",
       "      <td>Hadi,King Salman,Mohammed bin Salman,President...</td>\n",
       "      <td>Houthi,Operation Decisive Storm,Saudi-led coal...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Saudi intervention Yemen,Houthi conflict</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MEA_2011_SYRIA_CONFLICT</td>\n",
       "      <td>Syrian Civil War Begins</td>\n",
       "      <td>2011-03-15</td>\n",
       "      <td>Conflict</td>\n",
       "      <td>Civil War</td>\n",
       "      <td>Proxy War</td>\n",
       "      <td>Middle East</td>\n",
       "      <td>Syria</td>\n",
       "      <td>Saudi Arabia</td>\n",
       "      <td>Russia,USA,Iran,Turkey,Saudi Arabia,Qatar</td>\n",
       "      <td>Assad,Obama,Abu Mohammed al-Jolani,Putin,Qasse...</td>\n",
       "      <td>Free Syrian Army,FSA,Daraa protests,ISIS,Wagne...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Syria civil war,Assad speech,Daraa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EUR_2020_NAGORNO_CONFLICT</td>\n",
       "      <td>Second Nagorno-Karabakh War</td>\n",
       "      <td>2020-09-27</td>\n",
       "      <td>Conflict</td>\n",
       "      <td>Interstate War</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Armenia</td>\n",
       "      <td>Azerbaijan</td>\n",
       "      <td>Russia,Turkey,Israel,Syrian mercenaries,Afghan...</td>\n",
       "      <td>Pashinyan,Aliyev,Putin</td>\n",
       "      <td>Nagorno-Karabakh,Artsakh,Armenian Army,Azerbai...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nagorno-Karabakh war,Armenia Azerbaijan conflict</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>EUR_2014_DONBAS_CONFLICT</td>\n",
       "      <td>Donbas Conflict Start</td>\n",
       "      <td>2014-04-06</td>\n",
       "      <td>Conflict</td>\n",
       "      <td>Hybrid War</td>\n",
       "      <td>Insurgency</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Ukraine</td>\n",
       "      <td>Russia</td>\n",
       "      <td>OSCE,France,Germany,USA,EU</td>\n",
       "      <td>Turchynov,Strelkov,Viktor Yanukovych,Petro Por...</td>\n",
       "      <td>Donetsk People's Republic,Luhansk People's Rep...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Donbas war,Ukraine separatists</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EUR_2014_CRIMEA_CONFLICT</td>\n",
       "      <td>Annexation of Crimea</td>\n",
       "      <td>2014-02-27</td>\n",
       "      <td>Conflict</td>\n",
       "      <td>Annexation</td>\n",
       "      <td>Hybrid War</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Ukraine</td>\n",
       "      <td>Russia</td>\n",
       "      <td>US,EU,NATO,UN,CIS,OSCE</td>\n",
       "      <td>Aksyonov,Putin,Oleksandr Turchynov,Viktor Yanu...</td>\n",
       "      <td>little green men,referendum,Supreme Council of...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Crimea annexation,Russia Crimea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>EAS_2017_KOREA_NOCONFLICT</td>\n",
       "      <td>Korean Peninsula Crisis</td>\n",
       "      <td>2017-04-8</td>\n",
       "      <td>No Conflict</td>\n",
       "      <td>Standoff</td>\n",
       "      <td>Brinkmanship</td>\n",
       "      <td>East Asia</td>\n",
       "      <td>North Korea</td>\n",
       "      <td>USA</td>\n",
       "      <td>China,Russia,Japan,UN,THAAD</td>\n",
       "      <td>Kim Jong Un,Trump,Moon Jae-in</td>\n",
       "      <td>DPRK,ICBM,fire and fury,Day of the Sun,UN Secu...</td>\n",
       "      <td>Corresponds to major military parade (Day of t...</td>\n",
       "      <td>North Korea missile,fire and fury,Trump Kim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MEA_2020_IRAN_NOCONFLICT</td>\n",
       "      <td>Soleimani Aftermath Crisis</td>\n",
       "      <td>2020-01-08</td>\n",
       "      <td>No Conflict</td>\n",
       "      <td>Brinkmanship</td>\n",
       "      <td>Limited Strike</td>\n",
       "      <td>Middle East</td>\n",
       "      <td>Iran</td>\n",
       "      <td>USA</td>\n",
       "      <td>Iran,US,Iraq,PMF,US Embassy in Baghdad</td>\n",
       "      <td>Soleimani,Trump,Khamenei,Abu Mahdi al-Muhandis...</td>\n",
       "      <td>IRGC,Quds Force,Ain al-Asad base,Iraqi Parliam...</td>\n",
       "      <td>Date of Iranian retaliatory missile strikes on...</td>\n",
       "      <td>Soleimani strike,Iran missile attack,World War 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>EUR_2021_UKRAINE_NOCONFLICT</td>\n",
       "      <td>Ukraine Troop Buildup</td>\n",
       "      <td>2021-04-15</td>\n",
       "      <td>No Conflict</td>\n",
       "      <td>Standoff</td>\n",
       "      <td>Military Drill</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Ukraine</td>\n",
       "      <td>Russia</td>\n",
       "      <td>NATO,Ukrainian Intelligence Service,US,EU,Bela...</td>\n",
       "      <td>Biden,Putin,Zelenskyy,Sergey Shoigu,Anotry Bli...</td>\n",
       "      <td>Russian drills,troop buildup,Donbas,US Intelli...</td>\n",
       "      <td>Represents peak media reporting of troop movem...</td>\n",
       "      <td>Ukraine border crisis,Russia troops buildup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SAS_2020_INDOCHINA_NOCONFLICT</td>\n",
       "      <td>India-China Border Standoff</td>\n",
       "      <td>2020-06-15</td>\n",
       "      <td>No Conflict</td>\n",
       "      <td>Border Clash</td>\n",
       "      <td>NaN</td>\n",
       "      <td>South Asia</td>\n",
       "      <td>India</td>\n",
       "      <td>China</td>\n",
       "      <td>US,Russia,Japan,Australia,Quad grouping,UN</td>\n",
       "      <td>Modi,Xi Jinping,General M.M. Narvane,Wei Fangh...</td>\n",
       "      <td>Galwan Valley,Ladakh,PLA,Indian Army,Into-Tibe...</td>\n",
       "      <td>Date of the deadly Galwan Valley skirmish, the...</td>\n",
       "      <td>India China border,Galwan Valley clash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>EUR_2015_TURKEYRUSSIA_NOCONFLICT</td>\n",
       "      <td>Russia-Turkey Jet Downing Crisis</td>\n",
       "      <td>2015-11-24</td>\n",
       "      <td>No Conflict</td>\n",
       "      <td>Brinkmanship</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Europe/Middle East</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>Russia</td>\n",
       "      <td>NATO,US,EU,Syria,Iran,UN</td>\n",
       "      <td>Erdogan,Putin,Sergey Lavrov,Ahmet Davutoğlu,Se...</td>\n",
       "      <td>Su-24 shootdown,Turkish Air Force,Russian Aero...</td>\n",
       "      <td>The date the Russian Su-24 was shot down by a ...</td>\n",
       "      <td>Turkey shoots down Russian jet,Su-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SAS_2019_PULWAMA_NOCONFLICT</td>\n",
       "      <td>Pulwama-Balakot Crisis</td>\n",
       "      <td>2019-02-26</td>\n",
       "      <td>No Conflict</td>\n",
       "      <td>Border Clash</td>\n",
       "      <td>Airstrike</td>\n",
       "      <td>South Asia</td>\n",
       "      <td>India</td>\n",
       "      <td>Pakistan</td>\n",
       "      <td>USA,China,Saudi Arabia,UAE,UN,Russia</td>\n",
       "      <td>Modi,Imran Khan,Ajit Doval,Abhinandan Varthama...</td>\n",
       "      <td>Pulwama attack,Balakot airstrike,Jaish-e-Moham...</td>\n",
       "      <td>Date of the Indian airstrike on Balakot, the p...</td>\n",
       "      <td>Balakot airstrike,India Pakistan tension</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>EAS_2012_SCARBOROUGH_NOCONFLICT</td>\n",
       "      <td>Scarborough Shoal Standoff</td>\n",
       "      <td>2012-04-10</td>\n",
       "      <td>No Conflict</td>\n",
       "      <td>Standoff</td>\n",
       "      <td>NaN</td>\n",
       "      <td>East Asia</td>\n",
       "      <td>China</td>\n",
       "      <td>Philippines</td>\n",
       "      <td>US,ASEAN,Vietnam,Malaysia,Brunei,Taiwan</td>\n",
       "      <td>Aquino III,Hu Jintao,Hillary Clinton,Yang Jiec...</td>\n",
       "      <td>Scarborough Shoal,naval standoff,Philippine Na...</td>\n",
       "      <td>Date the naval standoff began when a Philippin...</td>\n",
       "      <td>Scarborough Shoal standoff,South China Sea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>AFR_2012_MALI_CONFLICT</td>\n",
       "      <td>Tuareg Rebellion Start</td>\n",
       "      <td>2012-01-17</td>\n",
       "      <td>Conflict</td>\n",
       "      <td>Insurgency</td>\n",
       "      <td>Civil War</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Mali</td>\n",
       "      <td>NaN</td>\n",
       "      <td>France,Algeria,Libya,UN,ECOWAS</td>\n",
       "      <td>Amadou Toumani Touré,Bilal Ag Acherif,Iyad Ag ...</td>\n",
       "      <td>MNLA,Ansar Dine,AQIM,Al-Qaeda in the Islamic M...</td>\n",
       "      <td>Date of the Battle of Menaka, one of the first...</td>\n",
       "      <td>Mali conflict,Tuareg rebellion,MNLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>SAS_2025_PHALGAMA_NOCONFLICT</td>\n",
       "      <td>Phalgam-Sindoor Crisis</td>\n",
       "      <td>2025-05-07</td>\n",
       "      <td>No Conflict</td>\n",
       "      <td>Limited Strike</td>\n",
       "      <td>Brinkmanship</td>\n",
       "      <td>South Asia</td>\n",
       "      <td>India</td>\n",
       "      <td>Pakistan</td>\n",
       "      <td>USA,China,UN,Russia</td>\n",
       "      <td>Modi,Shehbaz Sharif,Antony Blinken,Vikram Misri</td>\n",
       "      <td>Pahalgam attack,Operation Sindoor,The Resistan...</td>\n",
       "      <td>Date of India's retaliatory strikes (Operation...</td>\n",
       "      <td>Phalgam attack,Operation Sindoor,India Pakista...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Event_ID                        Event_Name  \\\n",
       "0          EUR_2022_UKRAINE_CONFLICT    Full-Scale Invasion of Ukraine   \n",
       "1             MEA_2023_GAZA_CONFLICT            Hamas Attack on Israel   \n",
       "2           AFR_2020_TIGRAY_CONFLICT                  Tigray War Start   \n",
       "3            AFR_2011_LIBYA_CONFLICT            Libyan Civil War Start   \n",
       "4          EUR_2008_GEORGIA_CONFLICT                Russo-Georgian War   \n",
       "5            MEA_2015_YEMEN_CONFLICT   Saudi-led Intervention in Yemen   \n",
       "6            MEA_2011_SYRIA_CONFLICT           Syrian Civil War Begins   \n",
       "7          EUR_2020_NAGORNO_CONFLICT       Second Nagorno-Karabakh War   \n",
       "8           EUR_2014_DONBAS_CONFLICT             Donbas Conflict Start   \n",
       "9           EUR_2014_CRIMEA_CONFLICT              Annexation of Crimea   \n",
       "10         EAS_2017_KOREA_NOCONFLICT           Korean Peninsula Crisis   \n",
       "11          MEA_2020_IRAN_NOCONFLICT        Soleimani Aftermath Crisis   \n",
       "12       EUR_2021_UKRAINE_NOCONFLICT             Ukraine Troop Buildup   \n",
       "13     SAS_2020_INDOCHINA_NOCONFLICT       India-China Border Standoff   \n",
       "14  EUR_2015_TURKEYRUSSIA_NOCONFLICT  Russia-Turkey Jet Downing Crisis   \n",
       "15       SAS_2019_PULWAMA_NOCONFLICT            Pulwama-Balakot Crisis   \n",
       "16   EAS_2012_SCARBOROUGH_NOCONFLICT        Scarborough Shoal Standoff   \n",
       "17            AFR_2012_MALI_CONFLICT            Tuareg Rebellion Start   \n",
       "18      SAS_2025_PHALGAMA_NOCONFLICT            Phalgam-Sindoor Crisis   \n",
       "\n",
       "    Event_Date      Outcome         Primary_Type        Secondary_Type  \\\n",
       "0   2022-02-24     Conflict             Invasion        Interstate War   \n",
       "1   2023-10-07     Conflict  Cross-border Attack        Asymmetric War   \n",
       "2   2020-11-04     Conflict            Civil War          Intervention   \n",
       "3   2011-02-15     Conflict            Civil War  Foreign Intervention   \n",
       "4   2008-08-07     Conflict             Invasion        Interstate War   \n",
       "5   2015-03-26     Conflict         Intervention             Proxy War   \n",
       "6   2011-03-15     Conflict            Civil War             Proxy War   \n",
       "7   2020-09-27     Conflict       Interstate War                   NaN   \n",
       "8   2014-04-06     Conflict           Hybrid War            Insurgency   \n",
       "9   2014-02-27     Conflict           Annexation            Hybrid War   \n",
       "10   2017-04-8  No Conflict             Standoff          Brinkmanship   \n",
       "11  2020-01-08  No Conflict         Brinkmanship        Limited Strike   \n",
       "12  2021-04-15  No Conflict             Standoff        Military Drill   \n",
       "13  2020-06-15  No Conflict         Border Clash                   NaN   \n",
       "14  2015-11-24  No Conflict         Brinkmanship                   NaN   \n",
       "15  2019-02-26  No Conflict         Border Clash             Airstrike   \n",
       "16  2012-04-10  No Conflict             Standoff                   NaN   \n",
       "17  2012-01-17     Conflict           Insurgency             Civil War   \n",
       "18  2025-05-07  No Conflict       Limited Strike          Brinkmanship   \n",
       "\n",
       "                Region    Country_1     Country_2  \\\n",
       "0               Europe      Ukraine        Russia   \n",
       "1          Middle East       Israel     Palestine   \n",
       "2               Africa     Ethiopia           NaN   \n",
       "3               Africa        Libya           NaN   \n",
       "4               Europe      Georgia        Russia   \n",
       "5          Middle East        Yemen  Saudi Arabia   \n",
       "6          Middle East        Syria  Saudi Arabia   \n",
       "7               Europe      Armenia    Azerbaijan   \n",
       "8               Europe      Ukraine        Russia   \n",
       "9               Europe      Ukraine        Russia   \n",
       "10           East Asia  North Korea           USA   \n",
       "11         Middle East         Iran           USA   \n",
       "12              Europe      Ukraine        Russia   \n",
       "13          South Asia        India         China   \n",
       "14  Europe/Middle East       Turkey        Russia   \n",
       "15          South Asia        India      Pakistan   \n",
       "16           East Asia        China   Philippines   \n",
       "17              Africa         Mali           NaN   \n",
       "18          South Asia        India      Pakistan   \n",
       "\n",
       "                                      External_Actors  \\\n",
       "0   Belarus,Chinese Hackers,International Criminal...   \n",
       "1                         Iran,IDF,Gaza,Islamic Jihad   \n",
       "2                Eritrea,militas from Amhara and Afar   \n",
       "3           NATO,Turkey,UAE,Egypt,France,Wagner Group   \n",
       "4   USA,NATO,France,Separatist authorities and arm...   \n",
       "5   United Arab Emirates, Egypt, Jordan, Morocco, ...   \n",
       "6           Russia,USA,Iran,Turkey,Saudi Arabia,Qatar   \n",
       "7   Russia,Turkey,Israel,Syrian mercenaries,Afghan...   \n",
       "8                          OSCE,France,Germany,USA,EU   \n",
       "9                              US,EU,NATO,UN,CIS,OSCE   \n",
       "10                        China,Russia,Japan,UN,THAAD   \n",
       "11             Iran,US,Iraq,PMF,US Embassy in Baghdad   \n",
       "12  NATO,Ukrainian Intelligence Service,US,EU,Bela...   \n",
       "13         US,Russia,Japan,Australia,Quad grouping,UN   \n",
       "14                           NATO,US,EU,Syria,Iran,UN   \n",
       "15               USA,China,Saudi Arabia,UAE,UN,Russia   \n",
       "16            US,ASEAN,Vietnam,Malaysia,Brunei,Taiwan   \n",
       "17                     France,Algeria,Libya,UN,ECOWAS   \n",
       "18                                USA,China,UN,Russia   \n",
       "\n",
       "                                      Key_Individuals  \\\n",
       "0   Putin,Zelenskyy,Biden,Alexander Bortnikov,Niko...   \n",
       "1                     Netanyahu,Sinwar,Mohammed Deif    \n",
       "2   Abiy Ahmed,Debretsion Gebremichael,Getachew Re...   \n",
       "3   Gaddafi,Mustafa Abdul Jalil,Khalifa Haftar,Fay...   \n",
       "4   Saakashvili,Medvedev,Putin,Borisov,Nicolas Sar...   \n",
       "5   Hadi,King Salman,Mohammed bin Salman,President...   \n",
       "6   Assad,Obama,Abu Mohammed al-Jolani,Putin,Qasse...   \n",
       "7                              Pashinyan,Aliyev,Putin   \n",
       "8   Turchynov,Strelkov,Viktor Yanukovych,Petro Por...   \n",
       "9   Aksyonov,Putin,Oleksandr Turchynov,Viktor Yanu...   \n",
       "10                      Kim Jong Un,Trump,Moon Jae-in   \n",
       "11  Soleimani,Trump,Khamenei,Abu Mahdi al-Muhandis...   \n",
       "12  Biden,Putin,Zelenskyy,Sergey Shoigu,Anotry Bli...   \n",
       "13  Modi,Xi Jinping,General M.M. Narvane,Wei Fangh...   \n",
       "14  Erdogan,Putin,Sergey Lavrov,Ahmet Davutoğlu,Se...   \n",
       "15  Modi,Imran Khan,Ajit Doval,Abhinandan Varthama...   \n",
       "16  Aquino III,Hu Jintao,Hillary Clinton,Yang Jiec...   \n",
       "17  Amadou Toumani Touré,Bilal Ag Acherif,Iyad Ag ...   \n",
       "18    Modi,Shehbaz Sharif,Antony Blinken,Vikram Misri   \n",
       "\n",
       "                                  Key_Groups_Entities  \\\n",
       "0   Kremlin,NATO,Russian Army,Ukrainian Army,Donet...   \n",
       "1   Hamas,Israel Defense Forces,Al-Qassam Brigades...   \n",
       "2   Tigray,TDF,ENDF,Eritrean Defence Forces,TPLF,IRAT   \n",
       "3   National Transitional Council,NTC,UNSC Resolut...   \n",
       "4   South Ossetia,Abkhazia,Georgian Armed forces,R...   \n",
       "5   Houthi,Operation Decisive Storm,Saudi-led coal...   \n",
       "6   Free Syrian Army,FSA,Daraa protests,ISIS,Wagne...   \n",
       "7   Nagorno-Karabakh,Artsakh,Armenian Army,Azerbai...   \n",
       "8   Donetsk People's Republic,Luhansk People's Rep...   \n",
       "9   little green men,referendum,Supreme Council of...   \n",
       "10  DPRK,ICBM,fire and fury,Day of the Sun,UN Secu...   \n",
       "11  IRGC,Quds Force,Ain al-Asad base,Iraqi Parliam...   \n",
       "12  Russian drills,troop buildup,Donbas,US Intelli...   \n",
       "13  Galwan Valley,Ladakh,PLA,Indian Army,Into-Tibe...   \n",
       "14  Su-24 shootdown,Turkish Air Force,Russian Aero...   \n",
       "15  Pulwama attack,Balakot airstrike,Jaish-e-Moham...   \n",
       "16  Scarborough Shoal,naval standoff,Philippine Na...   \n",
       "17  MNLA,Ansar Dine,AQIM,Al-Qaeda in the Islamic M...   \n",
       "18  Pahalgam attack,Operation Sindoor,The Resistan...   \n",
       "\n",
       "                                   Date_Justification  \\\n",
       "0                                                 NaN   \n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "5                                                 NaN   \n",
       "6                                                 NaN   \n",
       "7                                                 NaN   \n",
       "8                                                 NaN   \n",
       "9                                                 NaN   \n",
       "10  Corresponds to major military parade (Day of t...   \n",
       "11  Date of Iranian retaliatory missile strikes on...   \n",
       "12  Represents peak media reporting of troop movem...   \n",
       "13  Date of the deadly Galwan Valley skirmish, the...   \n",
       "14  The date the Russian Su-24 was shot down by a ...   \n",
       "15  Date of the Indian airstrike on Balakot, the p...   \n",
       "16  Date the naval standoff began when a Philippin...   \n",
       "17  Date of the Battle of Menaka, one of the first...   \n",
       "18  Date of India's retaliatory strikes (Operation...   \n",
       "\n",
       "                                         Search_Terms  \n",
       "0   Ukraine invasion,Russia special military opera...  \n",
       "1              Hamas attack,Iron Swords,Gaza invasion  \n",
       "2             Tigray war,Ethiopia conflict,Abiy Ahmed  \n",
       "3    Libya civil war,Gaddafi speech,Benghazi uprising  \n",
       "4           Russo-Georgian war,South Ossetia conflict  \n",
       "5            Saudi intervention Yemen,Houthi conflict  \n",
       "6                  Syria civil war,Assad speech,Daraa  \n",
       "7    Nagorno-Karabakh war,Armenia Azerbaijan conflict  \n",
       "8                      Donbas war,Ukraine separatists  \n",
       "9                     Crimea annexation,Russia Crimea  \n",
       "10        North Korea missile,fire and fury,Trump Kim  \n",
       "11   Soleimani strike,Iran missile attack,World War 3  \n",
       "12        Ukraine border crisis,Russia troops buildup  \n",
       "13             India China border,Galwan Valley clash  \n",
       "14               Turkey shoots down Russian jet,Su-24  \n",
       "15           Balakot airstrike,India Pakistan tension  \n",
       "16         Scarborough Shoal standoff,South China Sea  \n",
       "17                Mali conflict,Tuareg rebellion,MNLA  \n",
       "18  Phalgam attack,Operation Sindoor,India Pakista...  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df =pd.read_csv(\"events.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f512cb46",
   "metadata": {},
   "source": [
    "### 1a What conflicts are we gonna use?\n",
    "this is provided in the events.csv file\n",
    "\n",
    "justifications for each column:\n",
    "- Event_ID: unique identifier for each event\n",
    "- Event_Name: name of the event\n",
    "- Event_Date: date of the event\n",
    "- Outcome: outcome of the event\n",
    "- Primary_Type: conflict or no conflict\n",
    "- Secondary_Type: further classifies what type of conflict it is- helpful for no conflict events, might help in analysis and visualisation\n",
    "- Region: region where the event took place\n",
    "- Country_1: country 1 - primary actor\n",
    "- Country_2: country 2 - primary actor (for example, if we look at the ongoing middle-east conflict, the US is playing a major role, but the conflict is strictly between Israel and Iran)\n",
    "- External_Actors: external actors\n",
    "- Key_Individuals: key individuals\n",
    "- Key_Groups_Entities: key groups/entities\n",
    "- Date_Justification: date justification \n",
    "    we take the point of peak escalation because ineffect, our model should be able to compare and decide when \"Tanks are lined up at the border\" leads to escalation or de-escalation.\n",
    "- Search_Terms: search terms\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2f075a",
   "metadata": {},
   "source": [
    "### NEWS REPORT COLLECTION\n",
    "there's good news and bad news:\n",
    "the good news is the Guardian API is beautiful- it's giving us plenty of data to work with\n",
    "\n",
    "the bad news is we can't say the same for the New York times api, it's givng us little to no data.\n",
    "\n",
    "At this point in the project, I'm making the concious decision to focus on the Guardian API and ignore the New York times api.\n",
    "This will evidently limit the generalization of our model, considering the Guardian is a UK based, left-leaning news source.\n",
    "However, this is a tradeoff I'm willing to make for the sake of progress.\n",
    "It should also be noted that while we're only considering a single source, we are arguably using the best available source (at my current state)- while I could use GDELT, it's not as user-friendly, and frankly this project isn't a thesis for my PhD, it's a personal project to learn and grow.\n",
    "\n",
    "TL;DR: we're only using the Guardian. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e7e0e0",
   "metadata": {},
   "source": [
    "# NEWS DATA COLLECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f778eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "# --- CONFIGURATION & CONSTANTS ---\n",
    "LEAD_UP_DAYS = 90\n",
    "DATA_DIR = \"raw_data\"\n",
    "EVENTS_FILE = \"events.csv\"\n",
    "\n",
    "# --- API HELPERS ---\n",
    "\n",
    "def build_query(event):\n",
    "    \"\"\"Builds a robust boolean query for the APIs.\"\"\"\n",
    "    \n",
    "    # 1. Country terms (must have at least one)\n",
    "    country_terms = f'({event[\"Country_1\"]}'\n",
    "    if pd.notna(event[\"Country_2\"]):\n",
    "        country_terms += f' OR {event[\"Country_2\"]}'\n",
    "    country_terms += ')'\n",
    "\n",
    "    # 2. Key entities (should have at least one)\n",
    "    actors = []\n",
    "    if pd.notna(event[\"Key_Individuals\"]):\n",
    "        actors.extend([f'{name.strip()}' for name in event[\"Key_Individuals\"].split(',')])\n",
    "    if  pd.notna(event[\"Key_Groups_Entities\"]):\n",
    "         actors.extend([f'{name.strip()}' for name in event[\"Key_Groups_Entities\"].split(',')])\n",
    "    \n",
    "    actor_terms = \" AND (\" + \" OR \".join(actors) + \")\" if actors else \"\"\n",
    "\n",
    "    # 3. Thematic terms (from the Search_Terms column)\n",
    "    theme_terms = \"\"\n",
    "    if  pd.notna(event[\"Search_Terms\"]):\n",
    "        themes = [f'{term.strip()}' for term in event[\"Search_Terms\"].split(',')]\n",
    "        theme_terms = \" AND (\" + \" OR \".join(themes) + \")\"\n",
    "\n",
    "    # Combine all parts\n",
    "    full_query = country_terms + actor_terms + theme_terms\n",
    "    return full_query\n",
    "\n",
    "def fetch_guardian_data(query, start_date, end_date):\n",
    "    \"\"\"Fetches data from The Guardian API, handling pagination.\"\"\"\n",
    "    print(\"  -> Fetching from The Guardian...\")\n",
    "    articles = []\n",
    "    page = 1\n",
    "    total_pages = 1\n",
    "    \n",
    "    while page <= total_pages:\n",
    "        params = {\n",
    "            'q': query,\n",
    "            'from-date': start_date,\n",
    "            'to-date': end_date,\n",
    "            'api-key': os.getenv('GUARDIAN_API_KEY'),\n",
    "            'page-size': 50,\n",
    "            'page': page,\n",
    "            'show-fields': 'bodyText'\n",
    "        }\n",
    "        try:\n",
    "            response = requests.get('https://content.guardianapis.com/search', params=params)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()['response']\n",
    "            \n",
    "            for item in data.get('results', []):\n",
    "                articles.append({\n",
    "                    'source': 'The Guardian',\n",
    "                    'date': item['webPublicationDate'],\n",
    "                    'headline': item['webTitle'],\n",
    "                    'snippet': item.get('fields', {}).get('bodyText', '')[:500] # Get first 500 chars of body - why?\n",
    "                })\n",
    "            \n",
    "            total_pages = data.get('pages', 1)\n",
    "            print(f\"     Got page {page}/{total_pages}...\")\n",
    "            page += 1\n",
    "            time.sleep(1) # IMPORTANT: Respect API rate limits\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"     Error fetching from The Guardian: {e}\")\n",
    "            break\n",
    "            \n",
    "    return articles\n",
    "\n",
    "def build_nyt_query_and_filter(event):\n",
    "    \"\"\"\n",
    "    Builds a more flexible query and a separate filter for the NYT.\n",
    "    Returns a tuple: (query, filter_query)\n",
    "    \"\"\"\n",
    "    # 1. The Filter Query (fq): Highly reliable for location\n",
    "    # We use the 'glocations' field in the NYT data.\n",
    "    glocations = []\n",
    "    if pd.notna(event[\"Country_1\"]):\n",
    "        glocations.append(f'\"{event[\"Country_1\"].upper()}\"')\n",
    "    if pd.notna(event[\"Country_2\"]):\n",
    "        glocations.append(f'\"{event[\"Country_2\"].upper()}\"')\n",
    "    filter_query = f'glocations:({\" OR \".join(glocations)})' if glocations else None\n",
    "\n",
    "    # 2. The Keyword Query (q): A flexible search for actors and themes\n",
    "    keywords = []\n",
    "    if pd.notna(event[\"Search_Terms\"]):\n",
    "        keywords.extend([f'\"{term.strip()}\"' for term in event[\"Search_Terms\"].split(',')])\n",
    "    if pd.notna(event[\"Key_Groups_Entities\"]):\n",
    "        # Add the first 2 key groups for relevance\n",
    "        keywords.extend([f'\"{term.strip()}\"' for term in event[\"Key_Groups_Entities\"].split(',')[:2]])\n",
    "        \n",
    "    keyword_query = \" OR \".join(keywords) if keywords else event['Event_Name'] # Fallback to event name\n",
    "    \n",
    "    return keyword_query, filter_query\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fa123eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Fetching from The Guardian...\n",
      "     Got page 1/1...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'source': 'The Guardian',\n",
       "  'date': '2020-09-27T10:25:21Z',\n",
       "  'headline': 'At least 16 dead in Armenia-Azerbaijan clashes over disputed region',\n",
       "  'snippet': 'At least 16 troops and civilians have been killed in the worst fighting between Azerbaijani and Armenian forces since 2016, raising fears of instability in a region that provides crucial transit routes for gas and oil to the international market. Armenia declared martial law and ordered the total mobilisation of its military on Sunday after claiming to have destroyed several Azerbaijani aircraft and tanks in early-morning clashes. It accused Azerbaijan of carrying out air and artillery attacks o'},\n",
       " {'source': 'The Guardian',\n",
       "  'date': '2020-07-26T05:31:15Z',\n",
       "  'headline': 'Moscow’s fruit stalls become frontline of a border skirmish  2,000 miles away',\n",
       "  'snippet': 'When Saribek Gevorkyan heard reports that Food City, a vast food distribution centre owned by entrepreneurs from Azerbaijan, had suddenly blocked Armenian farmers and turned away 50 truckloads of fresh apricots, he took action. He offered space for free in his own shopping centre to the farmers, helping to host a fruit rescue mission that its organisers have dubbed “Operation Apricot”. “We told our friends that in the Russian Federation nobody can close their doors to us Armenians,” boomed Gevor'}]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_date = datetime.strptime(df.loc[7]['Event_Date'], '%Y-%m-%d')\n",
    "start_datetime = event_date - timedelta(days=LEAD_UP_DAYS)\n",
    "\n",
    "start_date_str = start_datetime.strftime('%Y-%m-%d')\n",
    "end_date_str = event_date.strftime('%Y-%m-%d')\n",
    "articles = fetch_guardian_data(build_nyt_query_and_filter(df.loc[7])[0], start_date_str, end_date_str)\n",
    "articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4b12ae60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "836"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c2a462ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Fetching from The New York Times...\n"
     ]
    }
   ],
   "source": [
    "start_date_nyt = start_datetime.strftime('%Y%m%d')\n",
    "end_date_nyt = event_date.strftime('%Y%m%d')\n",
    "data =fetch_nyt_data(build_nyt_query_and_filter(df.loc[0]), start_date_nyt, end_date_nyt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cae36021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'abstract': 'If the West fails to meet its security demands, Moscow could take measures like placing nuclear missiles close to the U.S. coastline, Russian officials have hinted.',\n",
       "  'byline': {'original': 'By Anton Troianovski and David E. Sanger'},\n",
       "  'document_type': 'article',\n",
       "  'headline': {'main': 'Russia Issues Subtle Threats More Far-Reaching Than a Ukraine Invasion',\n",
       "   'kicker': '',\n",
       "   'print_headline': 'Putin Could Cause Trouble Not Just in Ukraine but in West, Too'},\n",
       "  '_id': 'nyt://article/73e801a9-d932-5899-96ec-11d092bbb45e',\n",
       "  'keywords': [{'name': 'Location', 'value': 'Russia', 'rank': 1},\n",
       "   {'name': 'Location', 'value': 'Ukraine', 'rank': 2},\n",
       "   {'name': 'Subject', 'value': 'Defense and Military Forces', 'rank': 3},\n",
       "   {'name': 'Subject', 'value': 'Cyberwarfare and Defense', 'rank': 4},\n",
       "   {'name': 'Organization',\n",
       "    'value': 'North Atlantic Treaty Organization',\n",
       "    'rank': 5},\n",
       "   {'name': 'Subject',\n",
       "    'value': 'United States International Relations',\n",
       "    'rank': 6},\n",
       "   {'name': 'Subject',\n",
       "    'value': 'United States Defense and Military Forces',\n",
       "    'rank': 7},\n",
       "   {'name': 'Person', 'value': 'Biden, Joseph R Jr', 'rank': 8},\n",
       "   {'name': 'Person', 'value': 'Putin, Vladimir V', 'rank': 9},\n",
       "   {'name': 'Location', 'value': 'Eastern Europe', 'rank': 10},\n",
       "   {'name': 'Subject', 'value': 'War and Armed Conflicts', 'rank': 11},\n",
       "   {'name': 'Subject', 'value': 'Nuclear Weapons', 'rank': 12},\n",
       "   {'name': 'Subject', 'value': 'International Relations', 'rank': 13}],\n",
       "  'multimedia': {'caption': 'Russian tanks took part in drills in Russia’s Rostov region near the border with Ukraine this week.',\n",
       "   'credit': 'Associated Press',\n",
       "   'default': {'url': 'https://static01.nyt.com/images/2022/01/15/world/15russia-options1/15russia-options1-articleLarge.jpg',\n",
       "    'height': 400,\n",
       "    'width': 600},\n",
       "   'thumbnail': {'url': 'https://static01.nyt.com/images/2022/01/15/world/15russia-options1/15russia-options1-thumbStandard.jpg',\n",
       "    'height': 75,\n",
       "    'width': 75}},\n",
       "  'news_desk': 'Foreign',\n",
       "  'print_page': '1',\n",
       "  'print_section': 'A',\n",
       "  'pub_date': '2022-01-16T08:00:12Z',\n",
       "  'section_name': 'World',\n",
       "  'snippet': 'If the West fails to meet its security demands, Moscow could take measures like placing nuclear missiles close to the U.S. coastline, Russian officials have hinted.',\n",
       "  'source': 'The New York Times',\n",
       "  'subsection_name': 'Europe',\n",
       "  'type_of_material': 'News',\n",
       "  'uri': 'nyt://article/73e801a9-d932-5899-96ec-11d092bbb45e',\n",
       "  'web_url': 'https://www.nytimes.com/2022/01/16/world/europe/russia-ukraine-invasion.html',\n",
       "  'word_count': 1697},\n",
       " {'abstract': 'Theatrical meetings and dubious battlefield reports have shaped the Kremlin’s narrative that war is being pushed on it by a United States determined to destroy Russia.',\n",
       "  'byline': {'original': 'By Anton Troianovski'},\n",
       "  'document_type': 'article',\n",
       "  'headline': {'main': 'Piece by Piece, Russia’s Rationale for a Ukraine Invasion Is Put in Place',\n",
       "   'kicker': '',\n",
       "   'print_headline': 'Gradually, Theatrically, Kremlin Puts in Place Its Rationale for Invasion'},\n",
       "  '_id': 'nyt://article/0d87e75f-78cb-5536-8c45-13a873955206',\n",
       "  'keywords': [{'name': 'Subject',\n",
       "    'value': 'Russian Invasion of Ukraine (2022)',\n",
       "    'rank': 1},\n",
       "   {'name': 'Subject', 'value': 'Defense and Military Forces', 'rank': 2},\n",
       "   {'name': 'Subject', 'value': 'Politics and Government', 'rank': 3},\n",
       "   {'name': 'Subject',\n",
       "    'value': 'United States International Relations',\n",
       "    'rank': 4},\n",
       "   {'name': 'Subject', 'value': 'Propaganda', 'rank': 5},\n",
       "   {'name': 'Subject', 'value': 'Television', 'rank': 6},\n",
       "   {'name': 'Subject', 'value': 'Rumors and Misinformation', 'rank': 7},\n",
       "   {'name': 'Organization',\n",
       "    'value': \"People's Militia (Donetsk People's Republic)\",\n",
       "    'rank': 8},\n",
       "   {'name': 'Person', 'value': 'Naryshkin, Sergei Y', 'rank': 9},\n",
       "   {'name': 'Person', 'value': 'Peskov, Dmitri S', 'rank': 10},\n",
       "   {'name': 'Person', 'value': 'Putin, Vladimir V', 'rank': 11},\n",
       "   {'name': 'Location', 'value': 'Donetsk (Ukraine)', 'rank': 12},\n",
       "   {'name': 'Location', 'value': 'Luhansk (Ukraine)', 'rank': 13},\n",
       "   {'name': 'Location', 'value': 'Russia', 'rank': 14},\n",
       "   {'name': 'Location', 'value': 'Ukraine', 'rank': 15}],\n",
       "  'multimedia': {'caption': 'People who fled from separatist territory in eastern Ukraine following Russian claims about an attack by Ukraine watching Mr. Putin speak on Monday night.',\n",
       "   'credit': 'Sergey Ponomarev for The New York Times',\n",
       "   'default': {'url': 'https://static01.nyt.com/images/2022/02/21/world/21russia-propaganda-end/21russia-propaganda-end-articleLarge.jpg',\n",
       "    'height': 400,\n",
       "    'width': 600},\n",
       "   'thumbnail': {'url': 'https://static01.nyt.com/images/2022/02/21/world/21russia-propaganda-end/21russia-propaganda-end-thumbStandard.jpg',\n",
       "    'height': 75,\n",
       "    'width': 75}},\n",
       "  'news_desk': 'Foreign',\n",
       "  'print_page': '12',\n",
       "  'print_section': 'A',\n",
       "  'pub_date': '2022-02-22T14:51:40Z',\n",
       "  'section_name': 'World',\n",
       "  'snippet': 'Theatrical meetings and dubious battlefield reports have shaped the Kremlin’s narrative that war is being pushed on it by a United States determined to destroy Russia.',\n",
       "  'source': 'The New York Times',\n",
       "  'subsection_name': 'Europe',\n",
       "  'type_of_material': 'News',\n",
       "  'uri': 'nyt://article/0d87e75f-78cb-5536-8c45-13a873955206',\n",
       "  'web_url': 'https://www.nytimes.com/2022/02/22/world/europe/putin-invading-ukraine.html',\n",
       "  'word_count': 1449},\n",
       " {'abstract': 'If he invades, President Vladimir V. Putin is inviting a new global struggle with the West. He should think about how the last one ended, analysts say.',\n",
       "  'byline': {'original': 'By Anton Troianovski'},\n",
       "  'document_type': 'article',\n",
       "  'headline': {'main': 'In Ukraine Crisis, the Looming Threat of a New Cold War',\n",
       "   'kicker': '',\n",
       "   'print_headline': 'Reigniting Cold War Despite Its Risks'},\n",
       "  '_id': 'nyt://article/8b399d87-b672-596c-800e-707acc675abc',\n",
       "  'keywords': [{'name': 'Location', 'value': 'Russia', 'rank': 1},\n",
       "   {'name': 'Location', 'value': 'Ukraine', 'rank': 2},\n",
       "   {'name': 'Subject',\n",
       "    'value': 'United States International Relations',\n",
       "    'rank': 3},\n",
       "   {'name': 'Subject', 'value': 'Cold War Era', 'rank': 4},\n",
       "   {'name': 'Organization',\n",
       "    'value': 'North Atlantic Treaty Organization',\n",
       "    'rank': 5},\n",
       "   {'name': 'Person', 'value': 'Biden, Joseph R Jr', 'rank': 6},\n",
       "   {'name': 'Person', 'value': 'Putin, Vladimir V', 'rank': 7},\n",
       "   {'name': 'Location', 'value': 'USSR (Former Soviet Union)', 'rank': 8},\n",
       "   {'name': 'Subject', 'value': 'War and Armed Conflicts', 'rank': 9}],\n",
       "  'multimedia': {'caption': 'A Ukrainian soldier on the front lines in eastern Ukraine, which is seen as a likely flashpoint in a broader war.',\n",
       "   'credit': 'Tyler Hicks/The New York Times',\n",
       "   'default': {'url': 'https://static01.nyt.com/images/2022/02/19/world/19ukraine-analysis01/merlin_202124355_116f9e28-9116-47ae-9848-7cbe7bb0518c-articleLarge.jpg',\n",
       "    'height': 400,\n",
       "    'width': 600},\n",
       "   'thumbnail': {'url': 'https://static01.nyt.com/images/2022/02/19/world/19ukraine-analysis01/19ukraine-analysis01-thumbStandard.jpg',\n",
       "    'height': 75,\n",
       "    'width': 75}},\n",
       "  'news_desk': 'Foreign',\n",
       "  'print_page': '1',\n",
       "  'print_section': 'A',\n",
       "  'pub_date': '2022-02-19T15:13:24Z',\n",
       "  'section_name': 'World',\n",
       "  'snippet': 'If he invades, President Vladimir V. Putin is inviting a new global struggle with the West. He should think about how the last one ended, analysts say.',\n",
       "  'source': 'The New York Times',\n",
       "  'subsection_name': 'Europe',\n",
       "  'type_of_material': 'News',\n",
       "  'uri': 'nyt://article/8b399d87-b672-596c-800e-707acc675abc',\n",
       "  'web_url': 'https://www.nytimes.com/2022/02/19/world/europe/ukraine-russia-crisis-new-cold-war.html',\n",
       "  'word_count': 1499},\n",
       " {'abstract': 'The Biden administration and its allies are developing new possible sanctions ahead of a series of meetings to defuse the crisis with Moscow.',\n",
       "  'byline': {'original': 'By David E. Sanger and Eric Schmitt'},\n",
       "  'document_type': 'article',\n",
       "  'headline': {'main': 'U.S. Details Costs of a Russian Invasion of Ukraine',\n",
       "   'kicker': '',\n",
       "   'print_headline': 'As Talks Loom, U.S. Draws a Line on Ukraine'},\n",
       "  '_id': 'nyt://article/526653df-90cd-59e3-aadf-81d3be18e3c9',\n",
       "  'keywords': [{'name': 'Location', 'value': 'Russia', 'rank': 1},\n",
       "   {'name': 'Location', 'value': 'Ukraine', 'rank': 2},\n",
       "   {'name': 'Person', 'value': 'Putin, Vladimir V', 'rank': 3},\n",
       "   {'name': 'Subject',\n",
       "    'value': 'United States International Relations',\n",
       "    'rank': 4},\n",
       "   {'name': 'Subject',\n",
       "    'value': 'United States Defense and Military Forces',\n",
       "    'rank': 5},\n",
       "   {'name': 'Person', 'value': 'Biden, Joseph R Jr', 'rank': 6},\n",
       "   {'name': 'Subject', 'value': 'Embargoes and Sanctions', 'rank': 7},\n",
       "   {'name': 'Subject', 'value': 'Defense and Military Forces', 'rank': 8},\n",
       "   {'name': 'Subject', 'value': 'War and Armed Conflicts', 'rank': 9},\n",
       "   {'name': 'Organization',\n",
       "    'value': 'North Atlantic Treaty Organization',\n",
       "    'rank': 10},\n",
       "   {'name': 'Subject', 'value': 'Cyberwarfare and Defense', 'rank': 11},\n",
       "   {'name': 'Subject',\n",
       "    'value': 'Banking and Financial Institutions',\n",
       "    'rank': 12},\n",
       "   {'name': 'Organization', 'value': 'SolarWinds', 'rank': 13},\n",
       "   {'name': 'Person', 'value': 'Sherman, Wendy R', 'rank': 14},\n",
       "   {'name': 'Organization',\n",
       "    'value': 'SWIFT (Society for Worldwide Interbank Financial Telecommunication)',\n",
       "    'rank': 15},\n",
       "   {'name': 'Subject',\n",
       "    'value': 'Russian Invasion of Ukraine (2022)',\n",
       "    'rank': 16}],\n",
       "  'multimedia': {'caption': 'Ukrainian soldiers at a combat position in Luhansk, Ukraine, on Tuesday. Diplomatic talks between the United States and Russia are scheduled for Monday in Geneva.',\n",
       "   'credit': 'Maksim Levin/Reuters',\n",
       "   'default': {'url': 'https://static01.nyt.com/images/2022/01/09/world/08dc-sanctions-jump/merlin_199916325_7d9a2f22-1196-4ca9-a26d-c05577bf96ae-articleLarge.jpg',\n",
       "    'height': 401,\n",
       "    'width': 600},\n",
       "   'thumbnail': {'url': 'https://static01.nyt.com/images/2022/01/09/world/08dc-sanctions-jump/08dc-sanctions4-thumbStandard.jpg',\n",
       "    'height': 75,\n",
       "    'width': 75}},\n",
       "  'news_desk': 'Washington',\n",
       "  'print_page': '1',\n",
       "  'print_section': 'A',\n",
       "  'pub_date': '2022-01-08T16:57:56Z',\n",
       "  'section_name': 'U.S.',\n",
       "  'snippet': 'The Biden administration and its allies are developing new possible sanctions ahead of a series of meetings to defuse the crisis with Moscow.',\n",
       "  'source': 'The New York Times',\n",
       "  'subsection_name': 'Politics',\n",
       "  'type_of_material': 'News',\n",
       "  'uri': 'nyt://article/526653df-90cd-59e3-aadf-81d3be18e3c9',\n",
       "  'web_url': 'https://www.nytimes.com/2022/01/08/us/politics/us-sanctions-russia-ukraine.html',\n",
       "  'word_count': 1904},\n",
       " {'abstract': '“There will be no invasion tomorrow,” the strongman leader of Belarus told reporters after watching artillery and warplanes from Russia and his country put on a noisy display of firepower.',\n",
       "  'byline': {'original': 'By Andrew Higgins'},\n",
       "  'document_type': 'article',\n",
       "  'headline': {'main': 'Belarusian leader says exercises with Russia are not a sign of an imminent invasion of Ukraine.',\n",
       "   'kicker': '',\n",
       "   'print_headline': ''},\n",
       "  '_id': 'nyt://article/abaafa0a-38d1-5e2b-aaa8-7f847515703b',\n",
       "  'keywords': [{'name': 'Location', 'value': 'Russia', 'rank': 1},\n",
       "   {'name': 'Location', 'value': 'Belarus', 'rank': 2},\n",
       "   {'name': 'Subject', 'value': 'Defense and Military Forces', 'rank': 3},\n",
       "   {'name': 'Person', 'value': 'Lukashenko, Aleksandr G', 'rank': 4}],\n",
       "  'multimedia': {'caption': 'President Aleksandr G. Lukashenko of Belarus speaking to journalists on Thursday during joint military exercises with\\xa0 Russia.',\n",
       "   'credit': 'Emile Ducke for The New York Times',\n",
       "   'default': {'url': 'https://static01.nyt.com/images/2022/02/17/world/17ukraine-briefing-belarus/merlin_202399977_a7b9608f-2a72-43f7-a38f-002fe365b317-articleLarge.jpg',\n",
       "    'height': 400,\n",
       "    'width': 600},\n",
       "   'thumbnail': {'url': 'https://static01.nyt.com/images/2022/02/17/world/17ukraine-briefing-belarus/merlin_202399977_a7b9608f-2a72-43f7-a38f-002fe365b317-thumbStandard.jpg',\n",
       "    'height': 75,\n",
       "    'width': 75}},\n",
       "  'news_desk': 'Foreign',\n",
       "  'print_page': '',\n",
       "  'print_section': '',\n",
       "  'pub_date': '2022-02-17T16:32:44Z',\n",
       "  'section_name': 'World',\n",
       "  'snippet': '“There will be no invasion tomorrow,” the strongman leader of Belarus told reporters after watching artillery and warplanes from Russia and his country put on a noisy display of firepower.',\n",
       "  'source': 'The New York Times',\n",
       "  'subsection_name': '',\n",
       "  'type_of_material': 'News',\n",
       "  'uri': 'nyt://article/abaafa0a-38d1-5e2b-aaa8-7f847515703b',\n",
       "  'web_url': 'https://www.nytimes.com/2022/02/17/world/ukraine-invasion-belarus.html',\n",
       "  'word_count': 474},\n",
       " {'abstract': 'The pressure on Kyiv mounted after a weekend of shelling and evacuations in the east, and the extension of war games in neighboring Belarus.',\n",
       "  'byline': {'original': 'By Valerie Hopkins'},\n",
       "  'document_type': 'article',\n",
       "  'headline': {'main': 'Poised on Border, Russia May Be Seeking Pretext for Ukraine Invasion, Officials Say',\n",
       "   'kicker': '',\n",
       "   'print_headline': 'No Easing of Pressure On Ukraine’s Borders'},\n",
       "  '_id': 'nyt://article/06c515cd-816e-5425-bc38-d285d9e8ff6d',\n",
       "  'keywords': [{'name': 'Subject',\n",
       "    'value': 'Russian Invasion of Ukraine (2022)',\n",
       "    'rank': 1},\n",
       "   {'name': 'Subject', 'value': 'Propaganda', 'rank': 2},\n",
       "   {'name': 'Subject', 'value': 'Defense and Military Forces', 'rank': 3},\n",
       "   {'name': 'Subject', 'value': 'International Relations', 'rank': 4},\n",
       "   {'name': 'Subject',\n",
       "    'value': 'United States International Relations',\n",
       "    'rank': 5},\n",
       "   {'name': 'Subject', 'value': 'Politics and Government', 'rank': 6},\n",
       "   {'name': 'Subject', 'value': 'Evacuations and Evacuees', 'rank': 7},\n",
       "   {'name': 'Location', 'value': 'Ukraine', 'rank': 8},\n",
       "   {'name': 'Location', 'value': 'Russia', 'rank': 9},\n",
       "   {'name': 'Person', 'value': 'Putin, Vladimir V', 'rank': 10},\n",
       "   {'name': 'Location', 'value': 'Belarus', 'rank': 11},\n",
       "   {'name': 'Location', 'value': 'Donetsk (Ukraine)', 'rank': 12}],\n",
       "  'multimedia': {'caption': 'Evacuees from the separatist-held region of eastern Ukraine on Sunday at a temporary shelter in Taganrog, Russia. Many were anxious about how long they might be displaced and about what might lie ahead.',\n",
       "   'credit': 'Sergey Ponomarev for The New York Times',\n",
       "   'default': {'url': 'https://static01.nyt.com/images/2022/02/20/world/20ukraine-ledeall1sub/merlin_202607607_af0d0fbb-24b8-44f2-9616-065e29db8706-articleLarge.jpg',\n",
       "    'height': 400,\n",
       "    'width': 600},\n",
       "   'thumbnail': {'url': 'https://static01.nyt.com/images/2022/02/20/world/20ukraine-ledeall1sub/20ukraine-ledeall1sub-thumbStandard.jpg',\n",
       "    'height': 75,\n",
       "    'width': 75}},\n",
       "  'news_desk': 'Foreign',\n",
       "  'print_page': '6',\n",
       "  'print_section': 'A',\n",
       "  'pub_date': '2022-02-20T22:41:40Z',\n",
       "  'section_name': 'World',\n",
       "  'snippet': 'The pressure on Kyiv mounted after a weekend of shelling and evacuations in the east, and the extension of war games in neighboring Belarus.',\n",
       "  'source': 'The New York Times',\n",
       "  'subsection_name': 'Europe',\n",
       "  'type_of_material': 'News',\n",
       "  'uri': 'nyt://article/06c515cd-816e-5425-bc38-d285d9e8ff6d',\n",
       "  'web_url': 'https://www.nytimes.com/2022/02/20/world/europe/ukraine-russia-belarus-putin.html',\n",
       "  'word_count': 1554},\n",
       " {'abstract': '',\n",
       "  'byline': {'original': 'By Anton Troianovski, Andrew E. Kramer, Lara Jakes and Katie Rogers'},\n",
       "  'document_type': 'article',\n",
       "  'headline': {'main': 'Biden warns Putin of ‘swift and severe’ costs of any Ukraine invasion.',\n",
       "   'kicker': '',\n",
       "   'print_headline': ''},\n",
       "  '_id': 'nyt://article/a341753b-4d60-548c-adfb-3848367ecf37',\n",
       "  'keywords': [],\n",
       "  'multimedia': {'caption': 'A Ukrainian soldier at a front-line position in Pisky, eastern Ukraine, this week.',\n",
       "   'credit': 'Photo by Tyler Hicks/The New York Times',\n",
       "   'default': {'url': 'https://static01.nyt.com/images/2022/02/12/world/12ukraine-briefing-lede02-Video/merlin_201714306_280b2abc-9ecb-4380-a4cc-4a275d9b2628-articleLarge.jpg',\n",
       "    'height': 400,\n",
       "    'width': 600},\n",
       "   'thumbnail': {'url': 'https://static01.nyt.com/images/2022/02/12/world/12ukraine-briefing-lede02-Video/merlin_201714306_280b2abc-9ecb-4380-a4cc-4a275d9b2628-thumbStandard.jpg',\n",
       "    'height': 75,\n",
       "    'width': 75}},\n",
       "  'news_desk': 'Foreign',\n",
       "  'print_page': '',\n",
       "  'print_section': '',\n",
       "  'pub_date': '2022-02-12T08:44:21Z',\n",
       "  'section_name': 'World',\n",
       "  'snippet': '',\n",
       "  'source': 'The New York Times',\n",
       "  'subsection_name': 'Europe',\n",
       "  'type_of_material': 'Live Blog Post',\n",
       "  'uri': 'nyt://article/a341753b-4d60-548c-adfb-3848367ecf37',\n",
       "  'web_url': 'https://www.nytimes.com/live/2022/02/12/world/russia-ukraine-news/biden-will-speak-with-putin-today-as-the-us-warns-of-a-possible-imminent-russian-attack-on-ukraine',\n",
       "  'word_count': 803}]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "'q': build_nyt_query(df.loc[0]),\n",
    "'begin_date': start_date_nyt,\n",
    "'end_date': end_date_nyt,\n",
    "'api-key': os.getenv('NYT_API_KEY'),\n",
    "'page': 0\n",
    "}\n",
    "response = requests.get('https://api.nytimes.com/svc/search/v2/articlesearch.json', params=params)\n",
    "data = response.json()['response']\n",
    "docs = data.get('docs', [])\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9d14483c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dad8417a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "# --- CONFIGURATION & CONSTANTS ---\n",
    "LEAD_UP_DAYS = 90\n",
    "DATA_DIR = \"raw_data\"\n",
    "EVENTS_FILE = \"events.csv\"\n",
    "\n",
    "# --- API HELPERS ---\n",
    "\n",
    "def build_query(event):\n",
    "    \"\"\"Builds a robust boolean query for the APIs.\"\"\"\n",
    "    \n",
    "    # 1. Country terms (must have at least one)\n",
    "    country_terms = f'({event[\"Country_1\"]}'\n",
    "    if pd.notna(event[\"Country_2\"]):\n",
    "        country_terms += f' OR {event[\"Country_2\"]}'\n",
    "    country_terms += ')'\n",
    "\n",
    "    # 2. Key entities (should have at least one)\n",
    "    actors = []\n",
    "    if pd.notna(event[\"Key_Individuals\"]):\n",
    "        actors.extend([f'{name.strip()}' for name in event[\"Key_Individuals\"].split(',')])\n",
    "    if  pd.notna(event[\"Key_Groups_Entities\"]):\n",
    "         actors.extend([f'{name.strip()}' for name in event[\"Key_Groups_Entities\"].split(',')])\n",
    "    \n",
    "    actor_terms = \" AND (\" + \" OR \".join(actors) + \")\" if actors else \"\"\n",
    "\n",
    "    # 3. Thematic terms (from the Search_Terms column)\n",
    "    theme_terms = \"\"\n",
    "    if  pd.notna(event[\"Search_Terms\"]):\n",
    "        themes = [f'{term.strip()}' for term in event[\"Search_Terms\"].split(',')]\n",
    "        theme_terms = \" AND (\" + \" OR \".join(themes) + \")\"\n",
    "\n",
    "    # Combine all parts\n",
    "    full_query = country_terms + actor_terms + theme_terms\n",
    "    return full_query\n",
    "\n",
    "def fetch_guardian_data(query, start_date, end_date):\n",
    "    \"\"\"Fetches data from The Guardian API, handling pagination.\"\"\"\n",
    "    print(\"  -> Fetching from The Guardian...\")\n",
    "    articles = []\n",
    "    page = 1\n",
    "    total_pages = 1\n",
    "    \n",
    "    while page <= total_pages:\n",
    "        params = {\n",
    "            'q': query,\n",
    "            'from-date': start_date,\n",
    "            'to-date': end_date,\n",
    "            'api-key': os.getenv('GUARDIAN_API_KEY'),\n",
    "            'page-size': 50,\n",
    "            'page': page,\n",
    "            'show-fields': 'bodyText'\n",
    "        }\n",
    "        try:\n",
    "            response = requests.get('https://content.guardianapis.com/search', params=params)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()['response']\n",
    "            \n",
    "            for item in data.get('results', []):\n",
    "                articles.append({\n",
    "                    'source': 'The Guardian',\n",
    "                    'date': item['webPublicationDate'],\n",
    "                    'headline': item['webTitle'],\n",
    "                    'snippet': item.get('fields', {}).get('bodyText', '')[:500] # Get first 500 chars of body - why?\n",
    "                })\n",
    "            \n",
    "            total_pages = data.get('pages', 1)\n",
    "            print(f\"     Got page {page}/{total_pages}...\")\n",
    "            page += 1\n",
    "            time.sleep(1) # IMPORTANT: Respect API rate limits\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"     Error fetching from The Guardian: {e}\")\n",
    "            break\n",
    "            \n",
    "    return articles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cbec7a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Event: EUR_2022_UKRAINE_CONFLICT - Full-Scale Invasion of Ukraine\n",
      "  -> Query: (Ukraine OR Russia) AND (Putin OR Zelenskyy OR Biden OR Alexander Bortnikov OR Nikolai Patrushev OR Yury Kovalchuk OR Andrii Sybiha OR Mark Rutte OR Kremlin OR NATO OR Russian Army OR Ukrainian Army O...\n",
      "  -> Fetching from The Guardian...\n",
      "     Got page 1/17...\n",
      "     Got page 2/17...\n",
      "     Got page 3/17...\n",
      "     Got page 4/17...\n",
      "     Got page 5/17...\n",
      "     Got page 6/17...\n",
      "     Got page 7/17...\n",
      "     Got page 8/17...\n",
      "     Got page 9/17...\n",
      "     Got page 10/17...\n",
      "     Got page 11/17...\n",
      "     Got page 12/17...\n",
      "     Got page 13/17...\n",
      "     Got page 14/17...\n",
      "     Got page 15/17...\n",
      "     Got page 16/17...\n",
      "     Got page 17/17...\n",
      "Success! Saved 836 articles to raw_data/EUR_2022_UKRAINE_CONFLICT.csv\n",
      "\n",
      "Processing Event: MEA_2023_GAZA_CONFLICT - Hamas Attack on Israel\n",
      "  -> Query: (Israel OR Palestine) AND (Netanyahu OR Sinwar OR Mohammed Deif OR Hamas OR Israel Defense Forces OR Al-Qassam Brigades OR Lions' Den OR PFLP) AND (Hamas attack OR Iron Swords OR Gaza invasion)...\n",
      "  -> Fetching from The Guardian...\n",
      "     Got page 1/2...\n",
      "     Got page 2/2...\n",
      "Success! Saved 84 articles to raw_data/MEA_2023_GAZA_CONFLICT.csv\n",
      "\n",
      "Processing Event: AFR_2020_TIGRAY_CONFLICT - Tigray War Start\n",
      "  -> Query: (Ethiopia) AND (Abiy Ahmed OR Debretsion Gebremichael OR Getachew Reda OR Filipos Woldeyohannes OR Tigray OR TDF OR ENDF OR Eritrean Defence Forces OR TPLF OR IRAT) AND (Tigray war OR Ethiopia conflic...\n",
      "  -> Fetching from The Guardian...\n",
      "     Got page 1/1...\n",
      "Success! Saved 10 articles to raw_data/AFR_2020_TIGRAY_CONFLICT.csv\n",
      "\n",
      "Processing Event: AFR_2011_LIBYA_CONFLICT - Libyan Civil War Start\n",
      "  -> Query: (Libya) AND (Gaddafi OR Mustafa Abdul Jalil OR Khalifa Haftar OR Fayez al-Sarraj OR Abdul Hamid Dbeibeh OR National Transitional Council OR NTC OR UNSC Resolution 1973 OR Wagner Group OR LNA OR NTC OR...\n",
      "  -> Fetching from The Guardian...\n",
      "     Got page 1/2...\n",
      "     Got page 2/2...\n",
      "Success! Saved 69 articles to raw_data/AFR_2011_LIBYA_CONFLICT.csv\n",
      "\n",
      "Processing Event: EUR_2008_GEORGIA_CONFLICT - Russo-Georgian War\n",
      "  -> Query: (Georgia OR Russia) AND (Saakashvili OR Medvedev OR Putin OR Borisov OR Nicolas Sarkozy OR South Ossetia OR Abkhazia OR Georgian Armed forces OR Russian Peacekeepers OR Russian Army OR Chechen OR Coss...\n",
      "  -> Fetching from The Guardian...\n",
      "     Got page 1/1...\n",
      "Success! Saved 23 articles to raw_data/EUR_2008_GEORGIA_CONFLICT.csv\n",
      "\n",
      "Processing Event: MEA_2015_YEMEN_CONFLICT - Saudi-led Intervention in Yemen\n",
      "  -> Query: (Yemen OR Saudi Arabia) AND (Hadi OR King Salman OR Mohammed bin Salman OR President Abdrabbuh Mansur Hadi OR Prince Fahd bin Turki Al Saud OR Houthi OR Operation Decisive Storm OR Saudi-led coalition...\n",
      "  -> Fetching from The Guardian...\n",
      "     Got page 1/9...\n",
      "     Got page 2/9...\n",
      "     Got page 3/9...\n",
      "     Got page 4/9...\n",
      "     Got page 5/9...\n",
      "     Got page 6/9...\n",
      "     Got page 7/9...\n",
      "     Got page 8/9...\n",
      "     Got page 9/9...\n",
      "Success! Saved 425 articles to raw_data/MEA_2015_YEMEN_CONFLICT.csv\n",
      "\n",
      "Processing Event: MEA_2011_SYRIA_CONFLICT - Syrian Civil War Begins\n",
      "  -> Query: (Syria OR Saudi Arabia) AND (Assad OR Obama OR Abu Mohammed al-Jolani OR Putin OR Qassem Soleimani OR Free Syrian Army OR FSA OR Daraa protests OR ISIS OR Wagner Group OR SDF OR HTS OR Syrian Armed Fo...\n",
      "  -> Fetching from The Guardian...\n",
      "     Got page 1/2...\n",
      "     Got page 2/2...\n",
      "Success! Saved 80 articles to raw_data/MEA_2011_SYRIA_CONFLICT.csv\n",
      "\n",
      "Processing Event: EUR_2020_NAGORNO_CONFLICT - Second Nagorno-Karabakh War\n",
      "  -> Query: (Armenia OR Azerbaijan) AND (Pashinyan OR Aliyev OR Putin OR Nagorno-Karabakh OR Artsakh OR Armenian Army OR Azerbaijani Army OR Russian Peacekeepers OR Turkish miliary advisers OR Mercenary Brigades(...\n",
      "  -> Fetching from The Guardian...\n",
      "     Error fetching from The Guardian: 400 Client Error: Bad Request for url: https://content.guardianapis.com/search?q=%28Armenia+OR+Azerbaijan%29+AND+%28Pashinyan+OR+Aliyev+OR+Putin+OR+Nagorno-Karabakh+OR+Artsakh+OR+Armenian+Army+OR+Azerbaijani+Army+OR+Russian+Peacekeepers+OR+Turkish+miliary+advisers+OR+Mercenary+Brigades%28Pakistan+OR+Afghan+OR+Syrian%29%29+AND+%28Nagorno-Karabakh+war+OR+Armenia+Azerbaijan+conflict%29&from-date=2020-06-29&to-date=2020-09-27&api-key=a9938c5d-9ec6-415e-80e0-aa9ac1a6a309&page-size=50&page=1&show-fields=bodyText\n",
      "Warning: No articles found for EUR_2020_NAGORNO_CONFLICT. An empty file will not be created.\n",
      "\n",
      "Processing Event: EUR_2014_DONBAS_CONFLICT - Donbas Conflict Start\n",
      "  -> Query: (Ukraine OR Russia) AND (Turchynov OR Strelkov OR Viktor Yanukovych OR Petro Poroshenko OR Donetsk People's Republic OR Luhansk People's Republic OR ATO OR Russian irregualars and mercenaries OR Ukrai...\n",
      "  -> Fetching from The Guardian...\n",
      "     Got page 1/18...\n",
      "     Got page 2/18...\n",
      "     Got page 3/18...\n",
      "     Got page 4/18...\n",
      "     Got page 5/18...\n",
      "     Got page 6/18...\n",
      "     Got page 7/18...\n",
      "     Got page 8/18...\n",
      "     Got page 9/18...\n",
      "     Got page 10/18...\n",
      "     Got page 11/18...\n",
      "     Got page 12/18...\n",
      "     Got page 13/18...\n",
      "     Got page 14/18...\n",
      "     Got page 15/18...\n",
      "     Got page 16/18...\n",
      "     Got page 17/18...\n",
      "     Got page 18/18...\n",
      "Success! Saved 886 articles to raw_data/EUR_2014_DONBAS_CONFLICT.csv\n",
      "\n",
      "Processing Event: EUR_2014_CRIMEA_CONFLICT - Annexation of Crimea\n",
      "  -> Query: (Ukraine OR Russia) AND (Aksyonov OR Putin OR Oleksandr Turchynov OR Viktor Yanukovych OR Valentina Matviyenko OR little green men OR referendum OR Supreme Council of Crimea OR Federal Security Servic...\n",
      "  -> Fetching from The Guardian...\n",
      "     Got page 1/4...\n",
      "     Got page 2/4...\n",
      "     Got page 3/4...\n",
      "     Got page 4/4...\n",
      "Success! Saved 174 articles to raw_data/EUR_2014_CRIMEA_CONFLICT.csv\n",
      "\n",
      "Processing Event: EAS_2017_KOREA_NOCONFLICT - Korean Peninsula Crisis\n",
      "  -> Query: (North Korea OR USA) AND (Kim Jong Un OR Trump OR Moon Jae-in OR DPRK OR ICBM OR fire and fury OR Day of the Sun OR UN Security Council OR US-South Kora Military Alliance OR North Korea's strategic mi...\n",
      "  -> Fetching from The Guardian...\n",
      "     Got page 1/13...\n",
      "     Got page 2/13...\n",
      "     Got page 3/13...\n",
      "     Got page 4/13...\n",
      "     Got page 5/13...\n",
      "     Got page 6/13...\n",
      "     Got page 7/13...\n",
      "     Got page 8/13...\n",
      "     Got page 9/13...\n",
      "     Got page 10/13...\n",
      "     Got page 11/13...\n",
      "     Got page 12/13...\n",
      "     Got page 13/13...\n",
      "Success! Saved 624 articles to raw_data/EAS_2017_KOREA_NOCONFLICT.csv\n",
      "\n",
      "Processing Event: MEA_2020_IRAN_NOCONFLICT - Soleimani Aftermath Crisis\n",
      "  -> Query: (Iran OR USA) AND (Soleimani OR Trump OR Khamenei OR Abu Mahdi al-Muhandis OR Mike Pompeo OR Mark Esper OR IRGC OR Quds Force OR Ain al-Asad base OR Iraqi Parliament OR US Embassy in Iraq OR US Centra...\n",
      "  -> Fetching from The Guardian...\n",
      "     Got page 1/6...\n",
      "     Got page 2/6...\n",
      "     Got page 3/6...\n",
      "     Got page 4/6...\n",
      "     Got page 5/6...\n",
      "     Got page 6/6...\n",
      "Success! Saved 278 articles to raw_data/MEA_2020_IRAN_NOCONFLICT.csv\n",
      "\n",
      "Processing Event: EUR_2021_UKRAINE_NOCONFLICT - Ukraine Troop Buildup\n",
      "  -> Query: (Ukraine OR Russia) AND (Biden OR Putin OR Zelenskyy OR Sergey Shoigu OR Anotry Blinken OR Jens Stoltenberg OR Russian drills OR troop buildup OR Donbas OR US Intelligence Community OR Belarusian Mili...\n",
      "  -> Fetching from The Guardian...\n",
      "     Got page 1/4...\n",
      "     Got page 2/4...\n",
      "     Got page 3/4...\n",
      "     Got page 4/4...\n",
      "Success! Saved 157 articles to raw_data/EUR_2021_UKRAINE_NOCONFLICT.csv\n",
      "\n",
      "Processing Event: SAS_2020_INDOCHINA_NOCONFLICT - India-China Border Standoff\n",
      "  -> Query: (India OR China) AND (Modi OR Xi Jinping OR General M.M. Narvane OR Wei Fanghe OR S. Jaishankar OR Wang Yi OR Galwan Valley OR Ladakh OR PLA OR Indian Army OR Into-Tibetian Border Police OR Indian Air...\n",
      "  -> Fetching from The Guardian...\n",
      "     Got page 1/7...\n",
      "     Got page 2/7...\n",
      "     Got page 3/7...\n",
      "     Got page 4/7...\n",
      "     Got page 5/7...\n",
      "     Got page 6/7...\n",
      "     Got page 7/7...\n",
      "Success! Saved 341 articles to raw_data/SAS_2020_INDOCHINA_NOCONFLICT.csv\n",
      "\n",
      "Processing Event: EUR_2015_TURKEYRUSSIA_NOCONFLICT - Russia-Turkey Jet Downing Crisis\n",
      "  -> Query: (Turkey OR Russia) AND (Erdogan OR Putin OR Sergey Lavrov OR Ahmet Davutoğlu OR Sergey Shoigu OR Jens Stoltenberg OR Su-24 shootdown OR Turkish Air Force OR Russian Aerospace Forces OR Syrian Armed Fo...\n",
      "  -> Fetching from The Guardian...\n",
      "     Got page 1/13...\n",
      "     Got page 2/13...\n",
      "     Got page 3/13...\n",
      "     Got page 4/13...\n",
      "     Got page 5/13...\n",
      "     Got page 6/13...\n",
      "     Got page 7/13...\n",
      "     Got page 8/13...\n",
      "     Got page 9/13...\n",
      "     Got page 10/13...\n",
      "     Got page 11/13...\n",
      "     Got page 12/13...\n",
      "     Got page 13/13...\n",
      "Success! Saved 642 articles to raw_data/EUR_2015_TURKEYRUSSIA_NOCONFLICT.csv\n",
      "\n",
      "Processing Event: SAS_2019_PULWAMA_NOCONFLICT - Pulwama-Balakot Crisis\n",
      "  -> Query: (India OR Pakistan) AND (Modi OR Imran Khan OR Ajit Doval OR Abhinandan Varthaman OR Masood Azhar OR Pulwama attack OR Balakot airstrike OR Jaish-e-Mohammed OR IAF OR CRPF OR Indian Ministry of Extern...\n",
      "  -> Fetching from The Guardian...\n",
      "     Got page 1/5...\n",
      "     Got page 2/5...\n",
      "     Got page 3/5...\n",
      "     Got page 4/5...\n",
      "     Got page 5/5...\n",
      "Success! Saved 218 articles to raw_data/SAS_2019_PULWAMA_NOCONFLICT.csv\n",
      "\n",
      "Processing Event: EAS_2012_SCARBOROUGH_NOCONFLICT - Scarborough Shoal Standoff\n",
      "  -> Query: (China OR Philippines) AND (Aquino III OR Hu Jintao OR Hillary Clinton OR Yang Jiechi OR Albert del Rosario OR Scarborough Shoal OR naval standoff OR Philippine Navy OR Chinese Maritime Surveillance O...\n",
      "  -> Fetching from The Guardian...\n",
      "     Got page 1/3...\n",
      "     Got page 2/3...\n",
      "     Got page 3/3...\n",
      "Success! Saved 112 articles to raw_data/EAS_2012_SCARBOROUGH_NOCONFLICT.csv\n",
      "\n",
      "Processing Event: AFR_2012_MALI_CONFLICT - Tuareg Rebellion Start\n",
      "  -> Query: (Mali) AND (Amadou Toumani Touré OR Bilal Ag Acherif OR Iyad Ag Ghay OR Moussa Ag Assarid OR Colonel Sanogo OR MNLA OR Ansar Dine OR AQIM OR Al-Qaeda in the Islamic Maghreb) AND (Mali conflict OR Tuar...\n",
      "  -> Fetching from The Guardian...\n",
      "     Got page 1/1...\n",
      "Success! Saved 6 articles to raw_data/AFR_2012_MALI_CONFLICT.csv\n",
      "\n",
      "Processing Event: SAS_2025_PHALGAMA_NOCONFLICT - Phalgam-Sindoor Crisis\n",
      "  -> Query: (India OR Pakistan) AND (Modi OR Shehbaz Sharif OR Antony Blinken OR Vikram Misri OR Pahalgam attack OR Operation Sindoor OR The Resistance Front OR TRF OR Indus Waters Treaty) AND (Phalgam attack OR ...\n",
      "  -> Fetching from The Guardian...\n",
      "     Got page 1/2...\n",
      "     Got page 2/2...\n",
      "Success! Saved 70 articles to raw_data/SAS_2025_PHALGAMA_NOCONFLICT.csv\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Main function to orchestrate the data acquisition process.\"\"\"\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    os.makedirs(DATA_DIR)\n",
    "\n",
    "events_df = pd.read_csv(EVENTS_FILE)\n",
    "\n",
    "for _, event in events_df.iterrows():\n",
    "    event_id = event['Event_ID']\n",
    "    output_filename = os.path.join(DATA_DIR, f\"{event_id}.csv\")\n",
    "\n",
    "    if os.path.exists(output_filename):\n",
    "        print(f\"Skipping {event_id}: Data file already exists.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nProcessing Event: {event_id} - {event['Event_Name']}\")\n",
    "\n",
    "    # Prepare dates and query\n",
    "    event_date = datetime.strptime(event['Event_Date'], '%Y-%m-%d')\n",
    "    start_datetime = event_date - timedelta(days=LEAD_UP_DAYS)\n",
    "    \n",
    "    start_date_str = start_datetime.strftime('%Y-%m-%d')\n",
    "    end_date_str = event_date.strftime('%Y-%m-%d')\n",
    "    \n",
    "    query = build_query(event)\n",
    "    print(f\"  -> Query: {query[:200]}...\") # Print first 200 chars of query\n",
    "\n",
    "    # Fetch data from all sources\n",
    "    guardian_articles = fetch_guardian_data( query, start_date_str, end_date_str)\n",
    "\n",
    "    # Combine and save\n",
    "    all_articles = guardian_articles \n",
    "    if all_articles:\n",
    "        df = pd.DataFrame(all_articles)\n",
    "        df.to_csv(output_filename, index=False, encoding='utf-8')\n",
    "        print(f\"Success! Saved {len(df)} articles to {output_filename}\")\n",
    "    else:\n",
    "        print(f\"Warning: No articles found for {event_id}. An empty file will not be created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5b359a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EUR_2022_UKRAINE_CONFLICT 836\n",
      "MEA_2023_GAZA_CONFLICT 84\n",
      "AFR_2020_TIGRAY_CONFLICT 10\n",
      "AFR_2011_LIBYA_CONFLICT 69\n",
      "EUR_2008_GEORGIA_CONFLICT 23\n",
      "MEA_2015_YEMEN_CONFLICT 425\n",
      "MEA_2011_SYRIA_CONFLICT 80\n",
      "EUR_2020_NAGORNO_CONFLICT not found- bad query- skipping,(barely enough data )\n",
      "EUR_2014_DONBAS_CONFLICT 886\n",
      "EUR_2014_CRIMEA_CONFLICT 174\n",
      "EAS_2017_KOREA_NOCONFLICT 624\n",
      "MEA_2020_IRAN_NOCONFLICT 278\n",
      "EUR_2021_UKRAINE_NOCONFLICT 157\n",
      "SAS_2020_INDOCHINA_NOCONFLICT 341\n",
      "EUR_2015_TURKEYRUSSIA_NOCONFLICT 642\n",
      "SAS_2019_PULWAMA_NOCONFLICT 218\n",
      "EAS_2012_SCARBOROUGH_NOCONFLICT 112\n",
      "AFR_2012_MALI_CONFLICT 6\n",
      "SAS_2025_PHALGAMA_NOCONFLICT 70\n"
     ]
    }
   ],
   "source": [
    "for event in events_df.iterrows():\n",
    "    #print(event['Event_ID'],len(pd.read_csv(f\"raw_data/{event['Event_ID']}.csv\")))\n",
    "    try:\n",
    "        print(event[1]['Event_ID'],len(pd.read_csv(f\"raw_data/{event[1]['Event_ID']}.csv\")))\n",
    "    except:\n",
    "        print(event[1]['Event_ID'],\"not found- bad query- skipping,(barely enough data )\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcf3d57",
   "metadata": {},
   "source": [
    "# PRUING and Processing raw_data\n",
    "we'll take a random sample of 500 records from events that have over 500 articles,\n",
    "those that don't we'll take all of them\n",
    "\n",
    "### reasoning:\n",
    "- when we have a huge imbalance in the volume of data we obtain for different events, it becomes increasingly difficult for the model to effectively train on the minority class.\n",
    "- a small example: if you're training a model to detect cats and elephands, and you have 1000 cat images and 100 elephant images, the model will be biased towards cats and will perform poorly on elephant detection; it'll think the elephant is a fat mutated cat- not ideal,\n",
    "\n",
    "it may seem like taking we're throwing away alot of data, and on the flipside, the disparity still exists, but, this is a tradeoff we're willing to make for the sake of model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c9361f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balancing dataset using the 'capping' strategy...\n",
      "  -> Processing MEA_2011_SYRIA_CONFLICT.csv...\n",
      "     Event has 80 articles. Using all of them.\n",
      "  -> Processing MEA_2015_YEMEN_CONFLICT.csv...\n",
      "     Event has 425 articles. Using all of them.\n",
      "  -> Processing SAS_2020_INDOCHINA_NOCONFLICT.csv...\n",
      "     Event has 341 articles. Using all of them.\n",
      "  -> Processing SAS_2019_PULWAMA_NOCONFLICT.csv...\n",
      "     Event has 218 articles. Using all of them.\n",
      "  -> Processing AFR_2011_LIBYA_CONFLICT.csv...\n",
      "     Event has 69 articles. Using all of them.\n",
      "  -> Processing EAS_2017_KOREA_NOCONFLICT.csv...\n",
      "     Event has 624 articles. Capping to 500.\n",
      "  -> Processing EAS_2012_SCARBOROUGH_NOCONFLICT.csv...\n",
      "     Event has 112 articles. Using all of them.\n",
      "  -> Processing EUR_2014_DONBAS_CONFLICT.csv...\n",
      "     Event has 886 articles. Capping to 500.\n",
      "  -> Processing MEA_2020_IRAN_NOCONFLICT.csv...\n",
      "     Event has 278 articles. Using all of them.\n",
      "  -> Processing SAS_2025_PHALGAMA_NOCONFLICT.csv...\n",
      "     Event has 70 articles. Using all of them.\n",
      "  -> Processing EUR_2021_UKRAINE_NOCONFLICT.csv...\n",
      "     Event has 157 articles. Using all of them.\n",
      "  -> Processing EUR_2014_CRIMEA_CONFLICT.csv...\n",
      "     Event has 174 articles. Using all of them.\n",
      "  -> Processing EUR_2015_TURKEYRUSSIA_NOCONFLICT.csv...\n",
      "     Event has 642 articles. Capping to 500.\n",
      "  -> Processing EUR_2022_UKRAINE_CONFLICT.csv...\n",
      "     Event has 836 articles. Capping to 500.\n",
      "  -> Processing MEA_2023_GAZA_CONFLICT.csv...\n",
      "     Event has 84 articles. Using all of them.\n",
      "\n",
      "--- Balancing Complete ---\n",
      "Total articles before balancing: 4996\n",
      "Total articles after balancing: 4008\n",
      "Balanced data saved to the 'processed_data' folder.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "RAW_DATA_DIR = \"raw_data\"\n",
    "PROCESSED_DATA_DIR = \"processed_data\"\n",
    "ARTICLE_CAP = 500  # The maximum number of articles we'll use per event\n",
    "RANDOM_STATE = 42  # Ensures our random sample is the same every time we run it\n",
    "\n",
    "def balance_data():\n",
    "    \"\"\"\n",
    "    Reads all raw CSVs, applies a cap to balance the dataset,\n",
    "    and saves the results to a new directory.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(PROCESSED_DATA_DIR):\n",
    "        os.makedirs(PROCESSED_DATA_DIR)\n",
    "\n",
    "    raw_files = [f for f in os.listdir(RAW_DATA_DIR) if f.endswith('.csv')]\n",
    "    \n",
    "    if not raw_files:\n",
    "        print(f\"Error: No CSV files found in the '{RAW_DATA_DIR}' directory.\")\n",
    "        return\n",
    "\n",
    "    print(\"Balancing dataset using the 'capping' strategy...\")\n",
    "    total_raw_articles = 0\n",
    "    total_processed_articles = 0\n",
    "\n",
    "    for filename in raw_files:\n",
    "        print(f\"  -> Processing {filename}...\")\n",
    "        \n",
    "        # Read the raw data\n",
    "        raw_filepath = os.path.join(RAW_DATA_DIR, filename)\n",
    "        df = pd.read_csv(raw_filepath)\n",
    "        \n",
    "        num_articles = len(df)\n",
    "        total_raw_articles += num_articles\n",
    "\n",
    "        # Apply the capping logic\n",
    "        if num_articles > ARTICLE_CAP:\n",
    "            print(f\"     Event has {num_articles} articles. Capping to {ARTICLE_CAP}.\")\n",
    "            # Take a reproducible random sample\n",
    "            processed_df = df.sample(n=ARTICLE_CAP, random_state=RANDOM_STATE)\n",
    "        else:\n",
    "            print(f\"     Event has {num_articles} articles. Using all of them.\")\n",
    "            processed_df = df\n",
    "        \n",
    "        total_processed_articles += len(processed_df)\n",
    "        \n",
    "        # Save the new balanced dataframe\n",
    "        processed_filepath = os.path.join(PROCESSED_DATA_DIR, filename)\n",
    "        processed_df.to_csv(processed_filepath, index=False, encoding='utf-8')\n",
    "\n",
    "    print(\"\\n--- Balancing Complete ---\")\n",
    "    print(f\"Total articles before balancing: {total_raw_articles}\")\n",
    "    print(f\"Total articles after balancing: {total_processed_articles}\")\n",
    "    print(f\"Balanced data saved to the '{PROCESSED_DATA_DIR}' folder.\")\n",
    "\n",
    "\n",
    "balance_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f583adf2",
   "metadata": {},
   "source": [
    "## FEATURE ENGINEERING\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d874eb23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vaderSentiment\n",
      "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl.metadata (572 bytes)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.11/site-packages (from vaderSentiment) (2.32.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests->vaderSentiment) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests->vaderSentiment) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests->vaderSentiment) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests->vaderSentiment) (2025.6.15)\n",
      "Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
      "Installing collected packages: vaderSentiment\n",
      "Successfully installed vaderSentiment-3.3.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "dfc91045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting sentiment analysis...\n",
      "  -> Processing MEA_2011_SYRIA_CONFLICT.csv...\n",
      "  -> Processing MEA_2015_YEMEN_CONFLICT.csv...\n",
      "  -> Processing SAS_2020_INDOCHINA_NOCONFLICT.csv...\n",
      "  -> Processing SAS_2019_PULWAMA_NOCONFLICT.csv...\n",
      "  -> Processing AFR_2011_LIBYA_CONFLICT.csv...\n",
      "  -> Processing EAS_2017_KOREA_NOCONFLICT.csv...\n",
      "  -> Processing EAS_2012_SCARBOROUGH_NOCONFLICT.csv...\n",
      "  -> Processing EUR_2014_DONBAS_CONFLICT.csv...\n",
      "  -> Processing MEA_2020_IRAN_NOCONFLICT.csv...\n",
      "  -> Processing SAS_2025_PHALGAMA_NOCONFLICT.csv...\n",
      "  -> Processing EUR_2021_UKRAINE_NOCONFLICT.csv...\n",
      "  -> Processing EUR_2014_CRIMEA_CONFLICT.csv...\n",
      "  -> Processing EUR_2015_TURKEYRUSSIA_NOCONFLICT.csv...\n",
      "  -> Processing EUR_2022_UKRAINE_CONFLICT.csv...\n",
      "  -> Processing MEA_2023_GAZA_CONFLICT.csv...\n",
      "\n",
      "--- Feature Engineering: Sentiment Analysis Complete ---\n",
      "New files with sentiment scores saved to the 'features' folder.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "PROCESSED_DATA_DIR = \"processed_data\"\n",
    "FEATURES_DIR = \"features\"\n",
    "\n",
    "def analyze_sentiment():\n",
    "    \"\"\"\n",
    "    Reads all processed CSVs, calculates sentiment for each article,\n",
    "    and saves the results to a new 'features' directory.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(FEATURES_DIR):\n",
    "        os.makedirs(FEATURES_DIR)\n",
    "\n",
    "    processed_files = [f for f in os.listdir(PROCESSED_DATA_DIR) if f.endswith('.csv')]\n",
    "    \n",
    "    if not processed_files:\n",
    "        print(f\"Error: No CSV files found in the '{PROCESSED_DATA_DIR}' directory.\")\n",
    "        return\n",
    "\n",
    "    # Initialize the VADER sentiment analyzer\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "    print(\"Starting sentiment analysis...\")\n",
    "\n",
    "    for filename in processed_files:\n",
    "        print(f\"  -> Processing {filename}...\")\n",
    "        \n",
    "        # Read the processed data\n",
    "        filepath = os.path.join(PROCESSED_DATA_DIR, filename)\n",
    "        df = pd.read_csv(filepath)\n",
    "        \n",
    "        # Prepare the text for analysis by combining headline and snippet\n",
    "        # We use .fillna('') to handle any potentially empty fields gracefully\n",
    "        df['text_to_analyze'] = df['headline'].fillna('') + ' ' + df['snippet'].fillna('')\n",
    "\n",
    "        # Define a function to get the compound sentiment score\n",
    "        def get_sentiment_score(text):\n",
    "            # The 'compound' score is a single, normalized score from -1 to +1\n",
    "            return analyzer.polarity_scores(text)['compound']\n",
    "\n",
    "        # Apply the function to our text column to create the new feature\n",
    "        # This will calculate the sentiment for every row in the dataframe\n",
    "        df['sentiment_compound'] = df['text_to_analyze'].apply(get_sentiment_score)\n",
    "        \n",
    "        # We can drop the temporary analysis column\n",
    "        df = df.drop(columns=['text_to_analyze'])\n",
    "        \n",
    "        # Save the new dataframe with the sentiment feature\n",
    "        features_filepath = os.path.join(FEATURES_DIR, filename)\n",
    "        df.to_csv(features_filepath, index=False, encoding='utf-8')\n",
    "\n",
    "    print(\"\\n--- Feature Engineering: Sentiment Analysis Complete ---\")\n",
    "    print(f\"New files with sentiment scores saved to the '{FEATURES_DIR}' folder.\")\n",
    "\n",
    "analyze_sentiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "638b1f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting feature engineering...\n",
      "  -> Processing MEA_2011_SYRIA_CONFLICT.csv...\n",
      "  -> Processing MEA_2015_YEMEN_CONFLICT.csv...\n",
      "  -> Processing SAS_2020_INDOCHINA_NOCONFLICT.csv...\n",
      "  -> Processing SAS_2019_PULWAMA_NOCONFLICT.csv...\n",
      "  -> Processing AFR_2011_LIBYA_CONFLICT.csv...\n",
      "  -> Processing EAS_2017_KOREA_NOCONFLICT.csv...\n",
      "  -> Processing EAS_2012_SCARBOROUGH_NOCONFLICT.csv...\n",
      "  -> Processing EUR_2014_DONBAS_CONFLICT.csv...\n",
      "  -> Processing MEA_2020_IRAN_NOCONFLICT.csv...\n",
      "  -> Processing SAS_2025_PHALGAMA_NOCONFLICT.csv...\n",
      "  -> Processing EUR_2021_UKRAINE_NOCONFLICT.csv...\n",
      "  -> Processing EUR_2014_CRIMEA_CONFLICT.csv...\n",
      "  -> Processing EUR_2015_TURKEYRUSSIA_NOCONFLICT.csv...\n",
      "  -> Processing EUR_2022_UKRAINE_CONFLICT.csv...\n",
      "  -> Processing MEA_2023_GAZA_CONFLICT.csv...\n"
     ]
    }
   ],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "KEYWORD_TIERS = {\n",
    "    1: ['tensions', 'dispute', 'protest', 'unrest', 'sanctions', 'diplomat', 'condemn', 'concern', 'warns'],\n",
    "    3: ['threat', 'mobilize', 'mobilization', 'mobilizing', 'drill', 'exercise', 'border', 'violation', 'standoff', 'brink'],\n",
    "    5: ['ultimatum', 'attack', 'airstrike', 'invasion', 'casualties', 'clashes', 'imminent', 'offensive', 'shelling']\n",
    "}\n",
    "CERTAINTY_KEYWORDS = {\n",
    "    1: ['will', 'confirms', 'is', 'fact', 'order', 'declares', 'announces', 'instructs', 'guarantees', 'unquestionably'],\n",
    "   -1: ['could', 'may', 'might', 'suggests', 'appears', 'reportedly', 'seems', 'potential', 'unconfirmed', 'possibly', 'perhaps']\n",
    "}\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "def get_sentiment_score(text):\n",
    "    # The 'compound' score is a single, normalized score from -1 to +1\n",
    "    return analyzer.polarity_scores(text)['compound']\n",
    "def calculate_rhetoric_score(text):\n",
    "    score = 0\n",
    "    # Convert text to lower case for case-insensitive matching\n",
    "    lower_text = text.lower()\n",
    "    \n",
    "    # Check for keywords from each tier and add points\n",
    "    for points, keywords in KEYWORD_TIERS.items():\n",
    "        for keyword in keywords:\n",
    "            if keyword in lower_text:\n",
    "                score += points\n",
    "    return score\n",
    "def calculate_certainty_score(text):\n",
    "    score = 0\n",
    "    lower_text = text.lower()\n",
    "    for points, keywords in CERTAINTY_KEYWORDS.items():\n",
    "        for keyword in keywords:\n",
    "            # We use split() to match whole words to avoid 'is' matching in 'this'\n",
    "            if keyword in lower_text.split():\n",
    "                score += points\n",
    "    return score\n",
    "\n",
    "def create_rhetoric_score():\n",
    "    if not os.path.exists(FEATURES_DIR):\n",
    "        os.makedirs(FEATURES_DIR)\n",
    "\n",
    "    processed_files = [f for f in os.listdir(PROCESSED_DATA_DIR) if f.endswith('.csv')]\n",
    "    \n",
    "    if not processed_files:\n",
    "        print(f\"Error: No CSV files found in the '{PROCESSED_DATA_DIR}' directory.\")\n",
    "        return\n",
    "\n",
    "    # Initialize the VADER sentiment analyzer\n",
    "    sentiment_analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "    print(\"Starting feature engineering...\")\n",
    "\n",
    "    for filename in processed_files:\n",
    "        print(f\"  -> Processing {filename}...\")\n",
    "        \n",
    "        filepath = os.path.join(PROCESSED_DATA_DIR, filename)\n",
    "        df = pd.read_csv(filepath)\n",
    "        \n",
    "        # Prepare the text for analysis (handles empty snippets)\n",
    "        df['text_to_analyze'] = df['headline'].fillna('') + ' ' + df['snippet'].fillna('')\n",
    "\n",
    "        df['sentiment_compound'] = df['text_to_analyze'].apply(get_sentiment_score)\n",
    "        df['rhetoric_score'] = df['text_to_analyze'].apply(calculate_rhetoric_score)\n",
    "        df['certainty_score'] = df['text_to_analyze'].apply(calculate_certainty_score)\n",
    "        \n",
    "        # We can drop the temporary analysis column\n",
    "        df = df.drop(columns=['text_to_analyze'])\n",
    "        features_filepath = os.path.join(FEATURES_DIR, filename)\n",
    "        df.to_csv(features_filepath, index=False, encoding='utf-8')\n",
    "    \n",
    "create_rhetoric_score()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64c6733",
   "metadata": {},
   "source": [
    "## What we've done so far\n",
    "\n",
    "Features:\n",
    "- raw sentiment analysis using vader (0-1 score)\n",
    "- conflict specific rhetoric score\n",
    "- certainty score\n",
    "\n",
    "aside from vader which uses a pre-trained model, \n",
    "the remaining features are built using simple principle: assign weights to words based on their implied meaning in this context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5723d55d",
   "metadata": {},
   "source": [
    "# Aggregating news reports into weekly buckets\n",
    "\n",
    "doing so will smoothen the data- effectivley getting rid of noise and outliers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7eb7597f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "FEATURES_DIR = \"features\"\n",
    "# Make sure this points to your final, pruned events file\n",
    "EVENTS_FILE = \"events.csv\" \n",
    "FINAL_OUTPUT_FILE = \"final_model_data.csv\"\n",
    "if not os.path.exists(FEATURES_DIR):\n",
    "    print(f\"Error: Directory '{FEATURES_DIR}' not found. Please run feature_engineering.py first.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b5b0a2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_event_data = []\n",
    "feature_files = [f for f in os.listdir(FEATURES_DIR) if f.endswith('.csv')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0627f19b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Aggregating MEA_2011_SYRIA_CONFLICT...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "event_id = feature_files[0].replace('.csv', '')\n",
    "print(f\"  -> Aggregating {event_id}...\")\n",
    "filepath = os.path.join(FEATURES_DIR, feature_files[0])\n",
    "df = pd.read_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f980ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date column to datetime objects\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "df['date'] = df['date'].dt.tz_localize(None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba4af0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_date = pd.to_datetime(event_info['Event_Date'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fc0443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting weekly aggregation...\n",
      "  -> Aggregating MEA_2011_SYRIA_CONFLICT...\n",
      "  -> Aggregating MEA_2015_YEMEN_CONFLICT...\n",
      "  -> Aggregating SAS_2020_INDOCHINA_NOCONFLICT...\n",
      "  -> Aggregating SAS_2019_PULWAMA_NOCONFLICT...\n",
      "  -> Aggregating AFR_2011_LIBYA_CONFLICT...\n",
      "  -> Aggregating EAS_2017_KOREA_NOCONFLICT...\n",
      "  -> Aggregating EAS_2012_SCARBOROUGH_NOCONFLICT...\n",
      "  -> Aggregating EUR_2014_DONBAS_CONFLICT...\n",
      "  -> Aggregating MEA_2020_IRAN_NOCONFLICT...\n",
      "  -> Aggregating SAS_2025_PHALGAMA_NOCONFLICT...\n",
      "  -> Aggregating EUR_2021_UKRAINE_NOCONFLICT...\n",
      "  -> Aggregating EUR_2014_CRIMEA_CONFLICT...\n",
      "  -> Aggregating EUR_2015_TURKEYRUSSIA_NOCONFLICT...\n",
      "  -> Aggregating EUR_2022_UKRAINE_CONFLICT...\n",
      "  -> Aggregating MEA_2023_GAZA_CONFLICT...\n",
      "\n",
      "--- Aggregation Complete ---\n",
      "Final model-ready data saved to 'final_model_data.csv'\n",
      "The final dataset has 177 rows.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# --- CONFIGURATION --- \n",
    "FEATURES_DIR = \"features\"\n",
    "# Make sure this points to your final, pruned events file\n",
    "EVENTS_FILE = \"events.csv\" \n",
    "FINAL_OUTPUT_FILE = \"final_model_data.csv\"\n",
    "\n",
    "def aggregate_weekly_features():\n",
    "    \"\"\"\n",
    "    Reads all feature files, aggregates them into weekly bins for each event,\n",
    "    and saves a single, model-ready CSV file.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(FEATURES_DIR):\n",
    "        print(f\"Error: Directory '{FEATURES_DIR}' not found. Please run feature_engineering.py first.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        events_df = pd.read_csv(EVENTS_FILE)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Events file '{EVENTS_FILE}' not found. Please double-check the filename.\")\n",
    "        return\n",
    "\n",
    "    all_event_data = []\n",
    "    feature_files = [f for f in os.listdir(FEATURES_DIR) if f.endswith('.csv')]\n",
    "    print(\"Starting weekly aggregation...\")\n",
    "\n",
    "    for filename in feature_files:\n",
    "        event_id = filename.replace('.csv', '')\n",
    "        print(f\"  -> Aggregating {event_id}...\")\n",
    "        \n",
    "        filepath = os.path.join(FEATURES_DIR, filename)\n",
    "        df = pd.read_csv(filepath)\n",
    "\n",
    "        # Convert date column to datetime objects\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        \n",
    "        df['date'] = df['date'].dt.tz_localize(None) # <-- ADD THIS LINE\n",
    "\n",
    "        # Get the event date from our main events file\n",
    "        event_info = events_df[events_df['Event_ID'] == event_id]\n",
    "        if event_info.empty:\n",
    "            print(f\"     Warning: No event info found for {event_id} in {EVENTS_FILE}. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        event_date = pd.to_datetime(event_info['Event_Date'].iloc[0])\n",
    "\n",
    "        # --- Calculate \"Week Before Event\" ---\n",
    "        df['days_before_event'] = (event_date - df['date']).dt.days\n",
    "        df['week_before_event'] = -(df['days_before_event'] // 7)\n",
    "\n",
    "        # Filter to only include the 12-week lead-up\n",
    "        df = df[(df['week_before_event'] >= -12) & (df['week_before_event'] <= -1)]\n",
    "        \n",
    "        if df.empty:\n",
    "            print(f\"     Warning: No articles found within the 12-week lead-up for {event_id}.\")\n",
    "            continue\n",
    "\n",
    "        aggregations = {\n",
    "            'sentiment_compound': ['mean', 'max', 'min', 'std'],\n",
    "            'rhetoric_score': ['mean', 'max', 'sum'],\n",
    "            'certainty_score': ['mean', 'sum'],\n",
    "            'headline': ['count'] \n",
    "        }\n",
    "\n",
    "        weekly_df = df.groupby('week_before_event').agg(aggregations).reset_index()\n",
    "        \n",
    "        weekly_df.columns = ['_'.join(col).strip() for col in weekly_df.columns.values]\n",
    "        weekly_df = weekly_df.rename(columns={'week_before_event_': 'week_before_event', 'headline_count': 'article_count'})\n",
    "\n",
    "        weekly_df['Event_ID'] = event_id\n",
    "        weekly_df['Outcome'] = event_info['Outcome'].iloc[0]\n",
    "        \n",
    "        all_event_data.append(weekly_df)\n",
    "\n",
    "    if not all_event_data:\n",
    "        print(\"\\nError: No data was aggregated. Please check your input files and paths.\")\n",
    "        return\n",
    "\n",
    "    final_df = pd.concat(all_event_data, ignore_index=True)\n",
    "\n",
    "    id_cols = ['Event_ID', 'Outcome', 'week_before_event', 'article_count']\n",
    "    feature_cols = sorted([col for col in final_df.columns if col not in id_cols])\n",
    "    final_df = final_df[id_cols + feature_cols]\n",
    "\n",
    "    final_df.to_csv(FINAL_OUTPUT_FILE, index=False, encoding='utf-8')\n",
    "\n",
    "    print(\"\\n--- Aggregation Complete ---\")\n",
    "    print(f\"Final model-ready data saved to '{FINAL_OUTPUT_FILE}'\")\n",
    "    print(f\"The final dataset has {len(final_df)} rows.\")\n",
    "\n",
    "aggregate_weekly_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217a60e3",
   "metadata": {},
   "source": [
    "# OKAY, MODELLING TIME!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e7427a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.7.0-cp311-cp311-macosx_12_0_arm64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: numpy>=1.22.0 in ./.venv/lib/python3.11/site-packages (from scikit-learn) (2.3.1)\n",
      "Collecting scipy>=1.8.0 (from scikit-learn)\n",
      "  Downloading scipy-1.16.0-cp311-cp311-macosx_14_0_arm64.whl.metadata (61 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.7.0-cp311-cp311-macosx_12_0_arm64.whl (10.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Downloading scipy-1.16.0-cp311-cp311-macosx_14_0_arm64.whl (20.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.8/20.8 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [scikit-learn][0m [scikit-learn]\n",
      "\u001b[1A\u001b[2KSuccessfully installed joblib-1.5.1 scikit-learn-1.7.0 scipy-1.16.0 threadpoolctl-3.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87e0f63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score\n",
    "\n",
    "MODEL_FILE = 'final_model_data.csv'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b453d4b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data prepared. Using 11 features.\n",
      "Dataset has 177 total weekly observations.\n",
      "Conflict cases: 82 | No Conflict cases: 95\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df = pd.read_csv(MODEL_FILE)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Model data file '{MODEL_FILE}' not found. Please run aggregate_features.py first.\")\n",
    "    \n",
    "\n",
    "# Handle potential missing values (e.g., in '_std' columns for weeks with 1 article)\n",
    "# We will fill these with 0 for simplicity.\n",
    "df = df.fillna(0)\n",
    "\n",
    "# --- 2. Feature Engineering & Selection ---\n",
    "# Our goal is to predict the 'Outcome' based on the weekly features.\n",
    "\n",
    "# Convert the 'Outcome' column to a binary format (0 or 1)\n",
    "df['Outcome_binary'] = df['Outcome'].apply(lambda x: 1 if x == 'Conflict' else 0)\n",
    "\n",
    "# The features for our model are all the numerical columns we created\n",
    "# We exclude identifiers like Event_ID and the original Outcome string\n",
    "features = [col for col in df.columns if col not in ['Event_ID', 'Outcome', 'Outcome_binary']]\n",
    "\n",
    "X = df[features]\n",
    "y = df['Outcome_binary']\n",
    "\n",
    "print(f\"Data prepared. Using {len(X.columns)} features.\")\n",
    "print(f\"Dataset has {len(df)} total weekly observations.\")\n",
    "print(f\"Conflict cases: {y.sum()} | No Conflict cases: {len(y) - y.sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab8fb61b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week_before_event</th>\n",
       "      <th>article_count</th>\n",
       "      <th>certainty_score_mean</th>\n",
       "      <th>certainty_score_sum</th>\n",
       "      <th>rhetoric_score_max</th>\n",
       "      <th>rhetoric_score_mean</th>\n",
       "      <th>rhetoric_score_sum</th>\n",
       "      <th>sentiment_compound_max</th>\n",
       "      <th>sentiment_compound_mean</th>\n",
       "      <th>sentiment_compound_min</th>\n",
       "      <th>sentiment_compound_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-12</td>\n",
       "      <td>11</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>9</td>\n",
       "      <td>0.6576</td>\n",
       "      <td>-0.294145</td>\n",
       "      <td>-0.9475</td>\n",
       "      <td>0.644075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-11</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>12</td>\n",
       "      <td>0.2732</td>\n",
       "      <td>-0.187175</td>\n",
       "      <td>-0.7096</td>\n",
       "      <td>0.503790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.8126</td>\n",
       "      <td>-0.892450</td>\n",
       "      <td>-0.9723</td>\n",
       "      <td>0.112925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.4588</td>\n",
       "      <td>-0.653450</td>\n",
       "      <td>-0.8481</td>\n",
       "      <td>0.275277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-8</td>\n",
       "      <td>11</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>8</td>\n",
       "      <td>0.7959</td>\n",
       "      <td>-0.610555</td>\n",
       "      <td>-0.9800</td>\n",
       "      <td>0.648782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>-5</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.9300</td>\n",
       "      <td>-0.930000</td>\n",
       "      <td>-0.9300</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>-4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8271</td>\n",
       "      <td>-0.209500</td>\n",
       "      <td>-0.8979</td>\n",
       "      <td>0.811816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>-3</td>\n",
       "      <td>8</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.4939</td>\n",
       "      <td>-0.243787</td>\n",
       "      <td>-0.9100</td>\n",
       "      <td>0.520639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>-2</td>\n",
       "      <td>12</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>3.083333</td>\n",
       "      <td>37</td>\n",
       "      <td>0.8271</td>\n",
       "      <td>-0.562625</td>\n",
       "      <td>-0.9643</td>\n",
       "      <td>0.589446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7579</td>\n",
       "      <td>0.271900</td>\n",
       "      <td>-0.5106</td>\n",
       "      <td>0.684257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>177 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     week_before_event  ...  sentiment_compound_std\n",
       "0                  -12  ...                0.644075\n",
       "1                  -11  ...                0.503790\n",
       "2                  -10  ...                0.112925\n",
       "3                   -9  ...                0.275277\n",
       "4                   -8  ...                0.648782\n",
       "..                 ...  ...                     ...\n",
       "172                 -5  ...                0.000000\n",
       "173                 -4  ...                0.811816\n",
       "174                 -3  ...                0.520639\n",
       "175                 -2  ...                0.589446\n",
       "176                 -1  ...                0.684257\n",
       "\n",
       "[177 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cda127dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      1\n",
       "2      1\n",
       "3      1\n",
       "4      1\n",
       "      ..\n",
       "172    1\n",
       "173    1\n",
       "174    1\n",
       "175    1\n",
       "176    1\n",
       "Name: Outcome_binary, Length: 177, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8229b437",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de2ea038",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d01640bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training complete.\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(class_weight='balanced', max_iter=10000, random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "print(\"Model training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d97a4b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Model Performance ---\n",
      "Model Accuracy on Test Set: 0.5833\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Evaluating Model Performance ---\")\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy on Test Set: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9bedae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mConfusion Matrix:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# A confusion matrix shows us what the model got right and what it got wrong.\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# [[True Negative, False Positive], [False Negative, True Positive]]\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28mprint\u001b[39m(confusion_matrix(y_test, \u001b[43my_pred\u001b[49m))\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mClassification Report:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(classification_report(y_test, y_pred, target_names=[\u001b[33m'\u001b[39m\u001b[33mNo Conflict\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mConflict\u001b[39m\u001b[33m'\u001b[39m]))\n",
      "\u001b[31mNameError\u001b[39m: name 'y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"\\nConfusion Matrix:\")\n",
    "# A confusion matrix shows us what the model got right and what it got wrong.\n",
    "# [[True Negative, False Positive], [False Negative, True Positive]]\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdb1694",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "\n",
    "\n",
    "we notice that the model is far better at predicting when coflict doesn't occur (referencing the high recall score (.75) for No conflict), versus when conflict does occur (referencing the low recall score (.35) for conflict). This goes to indicate that the model is cautious in nature- potentially reflecting the nature of the singular news source we're conducting our study on. Aditionally, we see that precision for both conflict and no conflict is marignally better than tossing a coin, showing that the model is from a researcher's point of view, doing as much as tossing a coin. While this was disappointing to take in, it showcases a powerful truth: News reports aren't magical crystal orbs. They are purely meant to inform and entertain. World politics is an infinitley complex system, and the onset of war is a decision that has hundreds of hands on the steering wheel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b90d025a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Model Interpretation: Most Important Features ---\n",
      "Top 10 features predicting 'Conflict' (Positive Coefficients):\n",
      "                    Feature  Coefficient  Abs_Coefficient\n",
      "6        rhetoric_score_sum     0.381210         0.381210\n",
      "2      certainty_score_mean     0.320235         0.320235\n",
      "1             article_count     0.309380         0.309380\n",
      "4        rhetoric_score_max     0.291488         0.291488\n",
      "10   sentiment_compound_std     0.232266         0.232266\n",
      "9    sentiment_compound_min     0.194844         0.194844\n",
      "8   sentiment_compound_mean     0.164528         0.164528\n",
      "5       rhetoric_score_mean     0.044161         0.044161\n",
      "\n",
      "Top 10 features predicting 'No Conflict' (Negative Coefficients):\n",
      "                  Feature  Coefficient  Abs_Coefficient\n",
      "7  sentiment_compound_max    -0.818650         0.818650\n",
      "3     certainty_score_sum    -0.381896         0.381896\n",
      "0       week_before_event    -0.152735         0.152735\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# --- 7. Interpret the Model - Find the \"Tipping Point\" ---\n",
    "print(\"\\n--- Model Interpretation: Most Important Features ---\")\n",
    "\n",
    "# Get the coefficients (the \"importance\" score) the model learned for each feature\n",
    "coefficients = model.coef_[0]\n",
    "\n",
    "# Create a DataFrame to view the features and their learned importance\n",
    "feature_importance = pd.DataFrame({'Feature': features, 'Coefficient': coefficients})\n",
    "\n",
    "# Sort by the absolute value of the coefficient to see the most impactful features\n",
    "feature_importance['Abs_Coefficient'] = np.abs(feature_importance['Coefficient'])\n",
    "feature_importance = feature_importance.sort_values(by='Abs_Coefficient', ascending=False)\n",
    "\n",
    "print(\"Top 10 features predicting 'Conflict' (Positive Coefficients):\")\n",
    "print(feature_importance[feature_importance['Coefficient'] > 0].head(10))\n",
    "\n",
    "print(\"\\nTop 10 features predicting 'No Conflict' (Negative Coefficients):\")\n",
    "print(feature_importance[feature_importance['Coefficient'] < 0].head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fa848b",
   "metadata": {},
   "source": [
    "# FEATURE IMPORTANCE\n",
    "\n",
    "coming to decoding how our model decided what it decided, we see a compelling reason as to why it was far more conservative in it's prediction. The one feature that the model deemed was most important when considering if war would break out was the rhetoric score sum. Weekly rhetoric ephasising conflict inherently makes sense. If terms like airstrikes and invasions are thrown around with scary regularity, it is reasonable to expect a grim future. However, we found that inspite of being the single greatest indicator, it was pretty bad at confirming the outcome. \n",
    "On the other hand, the sentiment compound max shows an absolute coefficint of .82. This means that the model found that high positive sentiment was a strong indicator of no conflict. It far surpassed any other feature on it's sheer ability to confirm the outcome. \n",
    "\n",
    "This presents yet another important truth: positive news has a much greater ability to confirm a stable future than negative news has to confirm a grim one. I find this beautiful. In a world where negativity pervades all around us, it is refreshing to see that focusing on the positive side of things can give as alot more hope than we otherwise would allow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "41adc1c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_estimators&nbsp;</td>\n",
       "            <td class=\"value\">100</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('criterion',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">criterion&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;gini&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_depth&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_split',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_samples_split&nbsp;</td>\n",
       "            <td class=\"value\">2</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_samples_leaf&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_weight_fraction_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_weight_fraction_leaf&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_features',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_features&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;sqrt&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaf_nodes',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_leaf_nodes&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_impurity_decrease',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_impurity_decrease&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('bootstrap',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">bootstrap&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('oob_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">oob_score&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">42</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">warm_start&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">class_weight&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;balanced&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('ccp_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">ccp_alpha&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_samples',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_samples&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotonic_cst',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">monotonic_cst&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', random_state=42)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42)\n",
    "model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "26279522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Model Performance ---\n",
      "Model Accuracy on Test Set: 0.5556\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " No Conflict       0.56      0.74      0.64        19\n",
      "    Conflict       0.55      0.35      0.43        17\n",
      "\n",
      "    accuracy                           0.56        36\n",
      "   macro avg       0.55      0.54      0.53        36\n",
      "weighted avg       0.55      0.56      0.54        36\n",
      "\n",
      "\n",
      "--- Model Interpretation: Top 15 Most Important Features ---\n",
      "                    Feature  Importance\n",
      "7    sentiment_compound_max    0.123030\n",
      "8   sentiment_compound_mean    0.111809\n",
      "10   sentiment_compound_std    0.109917\n",
      "5       rhetoric_score_mean    0.109721\n",
      "9    sentiment_compound_min    0.094799\n",
      "2      certainty_score_mean    0.094264\n",
      "1             article_count    0.091940\n",
      "6        rhetoric_score_sum    0.075023\n",
      "0         week_before_event    0.065388\n",
      "4        rhetoric_score_max    0.062862\n",
      "3       certainty_score_sum    0.061247\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Evaluating Model Performance ---\")\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy on Test Set: {accuracy:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['No Conflict', 'Conflict']))\n",
    "\n",
    "# --- 6. Interpret the Model - Feature Importance ---\n",
    "print(\"\\n--- Model Interpretation: Top 15 Most Important Features ---\")\n",
    "\n",
    "# Random Forest has a built-in way to measure feature importance\n",
    "importances = model.feature_importances_\n",
    "\n",
    "# Create a DataFrame to view the features and their learned importance\n",
    "feature_importance = pd.DataFrame({'Feature': features, 'Importance': importances})\n",
    "\n",
    "# Sort by importance\n",
    "feature_importance = feature_importance.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(feature_importance.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd7e6d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "[[14  5]\n",
      " [11  6]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nConfusion Matrix:\")\n",
    "# A confusion matrix shows us what the model got right and what it got wrong.\n",
    "# [[True Negative, False Positive], [False Negative, True Positive]]\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0b8a53",
   "metadata": {},
   "source": [
    "# GRAPHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570af8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating Visualizations ---\n",
      "-> Saved visual_3_confusion_matrix.png\n",
      "-> Saved visual_4_feature_importance.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v8/1wyl6_ks02s620m7tv5drmch0000gn/T/ipykernel_94179/2501087468.py:52: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x='Coefficient', y='Feature', data=features_df, palette=colors, orient='h')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Saved visual_5_tipping_point_plot.png\n",
      "\n",
      "--- All visualizations generated successfully! ---\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# --- Configuration ---\n",
    "MODEL_DATA_FILE = \"final_model_data.csv\"\n",
    "# These are the results from your Logistic Regression model run\n",
    "CONFUSION_MATRIX_VALUES = [[15, 4], [11, 6]]\n",
    "FEATURE_COEFFICIENTS = {\n",
    "    \"rhetoric_score_sum\": 0.381,\n",
    "    \"certainty_score_mean\": 0.320,\n",
    "    \"article_count\": 0.309,\n",
    "    \"rhetoric_score_max\": 0.291,\n",
    "    \"sentiment_compound_std\": 0.232,\n",
    "    \"sentiment_compound_min\": 0.195,\n",
    "    \"sentiment_compound_mean\": 0.165,\n",
    "    \"rhetoric_score_mean\": 0.044,\n",
    "    \"sentiment_compound_max\": -0.819,\n",
    "    \"certainty_score_sum\": -0.382,\n",
    "    \"week_before_event\": -0.153\n",
    "}\n",
    "\n",
    "def create_visuals():\n",
    "    \"\"\"\n",
    "    Generates and saves the key visualizations for the project analysis.\n",
    "    \"\"\"\n",
    "    print(\"--- Generating Visualizations ---\")\n",
    "    \n",
    "    # --- Visual #3: Confusion Matrix Heatmap ---\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.set(font_scale=1.2)\n",
    "    ax = sns.heatmap(CONFUSION_MATRIX_VALUES, annot=True, fmt='g', cmap='Blues',\n",
    "                     cbar=False)\n",
    "    ax.set_title('Model Performance: The Crystal Ball is Broken\\n', fontsize=16)\n",
    "    ax.set_xlabel('Predicted Outcome', labelpad=15)\n",
    "    ax.set_ylabel('Actual Outcome', labelpad=15)\n",
    "    ax.xaxis.set_ticklabels(['No Conflict', 'Conflict'])\n",
    "    ax.yaxis.set_ticklabels(['No Conflict', 'Conflict'])\n",
    "    plt.savefig('visual_3_confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"-> Saved visual_3_confusion_matrix.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # --- Visual #4: Feature Importance Bar Chart ---\n",
    "    features_df = pd.DataFrame(FEATURE_COEFFICIENTS.items(), columns=['Feature', 'Coefficient'])\n",
    "    features_df['Abs_Coefficient'] = features_df['Coefficient'].abs()\n",
    "    features_df = features_df.sort_values(by='Abs_Coefficient', ascending=False)\n",
    "    \n",
    "    colors = ['#2ca02c' if c < 0 else '#d62728' for c in features_df['Coefficient']]\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.barplot(x='Coefficient', y='Feature', data=features_df, palette=colors, orient='h')\n",
    "    plt.title('The \"Brain\" of the Model: What Predicts Conflict vs. Peace?', fontsize=16, pad=20)\n",
    "    plt.xlabel('Coefficient (Impact on Prediction)', labelpad=15)\n",
    "    plt.ylabel('Rhetorical Feature', labelpad=15)\n",
    "    plt.axvline(0, color='black', linewidth=0.8)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('visual_4_feature_importance.png', dpi=300)\n",
    "    print(\"-> Saved visual_4_feature_importance.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # --- Visual #5: \"Tipping Point\" Time-Series Plot ---\n",
    "    try:\n",
    "        df = pd.read_csv(MODEL_DATA_FILE)\n",
    "        \n",
    "        # Select two contrasting events to plot\n",
    "        conflict_event = df[df['Event_ID'] == 'EUR_2022_UKRAINE_CONFLICT']\n",
    "        no_conflict_event = df[df['Event_ID'] == 'EAS_2017_KOREA_NOCONFLICT']\n",
    "\n",
    "        plt.figure(figsize=(12, 7))\n",
    "        sns.lineplot(x='week_before_event', y='sentiment_compound_max', data=conflict_event, \n",
    "                     label='Ukraine 2022 (Conflict)', color='#d62728', marker='o')\n",
    "        sns.lineplot(x='week_before_event', y='sentiment_compound_max', data=no_conflict_event, \n",
    "                     label='Korea 2017 (No Conflict)', color='#2ca02c', marker='o')\n",
    "        \n",
    "        plt.title('The \"Off-Ramp\" Signal: Tracking Hopeful Language Over Time', fontsize=16, pad=20)\n",
    "        plt.xlabel('Weeks Before Peak Tension / Invasion', labelpad=15)\n",
    "        plt.ylabel('Maximum Sentiment Score (Hopefulness)', labelpad=15)\n",
    "        plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "        plt.axhline(0, color='black', linewidth=0.8, linestyle='--')\n",
    "        plt.legend()\n",
    "        plt.xticks(range(-12, 0, 1))\n",
    "        plt.savefig('visual_5_tipping_point_plot.png', dpi=300, bbox_inches='tight')\n",
    "        print(\"-> Saved visual_5_tipping_point_plot.png\")\n",
    "        plt.close()\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"-> Skipped Visual #5: Could not find '{MODEL_DATA_FILE}'. Please ensure it exists.\")\n",
    "\n",
    "\n",
    "    print(\"\\n--- All visualizations generated successfully! ---\")\n",
    "\n",
    "\n",
    "\n",
    "create_visuals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed5beb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating Trend Visualizations ---\n",
      "-> Saved visual_6_spaghetti_plot.png\n",
      "-> Saved visual_7_average_trend_plot.png\n",
      "\n",
      "--- Trend visualizations generated successfully! ---\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os \n",
    "# --- Configuration ---\n",
    "MODEL_DATA_FILE = \"final_model_data.csv\"\n",
    "\n",
    "def create_trend_visuals():\n",
    "    \"\"\"\n",
    "    Generates and saves trend visualizations for the project analysis.\n",
    "    \"\"\"\n",
    "    print(\"--- Generating Trend Visualizations ---\")\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(MODEL_DATA_FILE)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"-> Could not find '{MODEL_DATA_FILE}'. Please ensure it exists.\")\n",
    "        return\n",
    "\n",
    "    # --- Visual #6: \"Spaghetti Plot\" of Max Sentiment for All Events ---\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    sns.set_style(\"darkgrid\")\n",
    "    \n",
    "    # Use hue for Outcome, and style for each Event_ID to make them distinct\n",
    "    ax = sns.lineplot(\n",
    "        x='week_before_event', \n",
    "        y='sentiment_compound_max', \n",
    "        data=df, \n",
    "        hue='Outcome',\n",
    "        style='Event_ID',\n",
    "        palette={'Conflict': '#d62728', 'No Conflict': '#2ca02c'},\n",
    "        markers=True,\n",
    "        legend='full'\n",
    "    )\n",
    "    \n",
    "    plt.title('Max Sentiment Trajectory for All Individual Crises', fontsize=18, pad=20)\n",
    "    plt.xlabel('Weeks Before Peak Tension / Event', labelpad=15)\n",
    "    plt.ylabel('Maximum Sentiment Score', labelpad=15)\n",
    "    plt.xticks(range(-12, 0, 1))\n",
    "    plt.axhline(0, color='black', linewidth=0.8, linestyle='--')\n",
    "    \n",
    "    # Move the legend outside the plot because it's very large\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0, 0.85, 1]) # Adjust layout to make room for legend\n",
    "    plt.savefig('visual_6_spaghetti_plot.png', dpi=300)\n",
    "    print(\"-> Saved visual_6_spaghetti_plot.png\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    # --- Visual #7: Average Trend of Mean Sentiment (More Insightful) ---\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    \n",
    "    # By not specifying 'style' or 'units', seaborn automatically calculates and plots the mean trend with a confidence interval\n",
    "    sns.lineplot(\n",
    "        x='week_before_event', \n",
    "        y='sentiment_compound_mean', # Using the more robust 'mean' feature\n",
    "        data=df, \n",
    "        hue='Outcome',\n",
    "        palette={'Conflict': '#d62728', 'No Conflict': '#2ca02c'},\n",
    "        marker='o'\n",
    "    )\n",
    "    \n",
    "    plt.title('Average Sentiment Trend: Conflict vs. No Conflict', fontsize=18, pad=20)\n",
    "    plt.xlabel('Weeks Before Peak Tension / Event', labelpad=15)\n",
    "    plt.ylabel('Average Weekly Sentiment Score', labelpad=15)\n",
    "    plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "    plt.axhline(0, color='black', linewidth=0.8, linestyle='--')\n",
    "    plt.legend(title='Outcome')\n",
    "    plt.xticks(range(-12, 0, 1))\n",
    "    \n",
    "    plt.savefig('visual_7_average_trend_plot.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"-> Saved visual_7_average_trend_plot.png\")\n",
    "    plt.close()\n",
    "\n",
    "    print(\"\\n--- Trend visualizations generated successfully! ---\")\n",
    "\n",
    "\n",
    "create_trend_visuals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8b085d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Data Forensics Report ---\n",
      "Investigating Top 5 'Positive' Headlines for 'EUR_2022_UKRAINE_CONFLICT' in Week -7\n",
      "\n",
      "Headline: Morning mail: Covid positive test rate hits new high, Canada’s mystery neurological illness, 2022 films\n",
      "Sentiment Score: 0.9257\n",
      "--------------------\n",
      "Headline: Biden to speak with Putin amid Russia’s increased presence near Ukraine\n",
      "Sentiment Score: 0.9022\n",
      "--------------------\n",
      "Headline: Russia ‘very likely’ to invade Ukraine without ‘enormous sanctions’ – Schiff\n",
      "Sentiment Score: 0.7096\n",
      "--------------------\n",
      "Headline: EU’s top diplomat visits Ukraine frontline in show of solidarity\n",
      "Sentiment Score: 0.2732\n",
      "--------------------\n",
      "Headline: France reports over 200,000 cases; eastern Europe’s death toll reaches 1 million – as it happened\n",
      "Sentiment Score: -0.1154\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "# Let's investigate the event and the specific week that had a positive spike.\n",
    "EVENT_TO_INSPECT = 'EUR_2022_UKRAINE_CONFLICT'\n",
    "WEEK_TO_INSPECT = -7 # The week with the high positive sentiment spike for 'Conflict'\n",
    "\n",
    "FEATURES_DIR = \"features\"\n",
    "EVENTS_FILE = \"events.csv\"\n",
    "\n",
    "def inspect_specific_week():\n",
    "    \"\"\"\n",
    "    Loads the feature data for a specific event and prints the most\n",
    "    positive headlines from a specific week to help us understand why\n",
    "    the average sentiment was high.\n",
    "    \"\"\"\n",
    "    event_filename = f\"{EVENT_TO_INSPECT}.csv\"\n",
    "    filepath = os.path.join(FEATURES_DIR, event_filename)\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(filepath)\n",
    "        events_df = pd.read_csv(EVENTS_FILE)\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: Could not find a necessary file. {e}\")\n",
    "        return\n",
    "\n",
    "    # --- Re-calculate the 'week_before_event' for our specific file ---\n",
    "    df['date'] = pd.to_datetime(df['date']).dt.tz_localize(None)\n",
    "    \n",
    "    event_info = events_df[events_df['Event_ID'] == EVENT_TO_INSPECT]\n",
    "    if event_info.empty:\n",
    "        print(f\"Error: Event ID {EVENT_TO_INSPECT} not found in {EVENTS_FILE}.\")\n",
    "        return\n",
    "        \n",
    "    event_date = pd.to_datetime(event_info['Event_Date'].iloc[0])\n",
    "    df['days_before_event'] = (event_date - df['date']).dt.days\n",
    "    df['week_before_event'] = -(df['days_before_event'] // 7)\n",
    "\n",
    "    # --- Filter down to the specific week we want to look at ---\n",
    "    week_df = df[df['week_before_event'] == WEEK_TO_INSPECT]\n",
    "\n",
    "    if week_df.empty:\n",
    "        print(f\"No articles found for Week {WEEK_TO_INSPECT} in {EVENT_TO_INSPECT}.\")\n",
    "        return\n",
    "\n",
    "    # Sort by sentiment score to see the most \"positive\" headlines\n",
    "    top_positive_headlines = week_df.sort_values(by='sentiment_compound', ascending=False).head(5)\n",
    "\n",
    "    print(\"--- Data Forensics Report ---\")\n",
    "    print(f\"Investigating Top 5 'Positive' Headlines for '{EVENT_TO_INSPECT}' in Week {WEEK_TO_INSPECT}\\n\")\n",
    "\n",
    "    for index, row in top_positive_headlines.iterrows():\n",
    "        print(f\"Headline: {row['headline']}\")\n",
    "        print(f\"Sentiment Score: {row['sentiment_compound']:.4f}\")\n",
    "        print(\"-\" * 20)\n",
    "\n",
    "\n",
    "inspect_specific_week()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212e2994",
   "metadata": {},
   "source": [
    "# yeah wth, we're getting data about covid, we need a relavance filter to parse again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84093d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Data Cleaning and Relevance Filtering ---\n",
      "  -> Cleaning EUR_2022_UKRAINE_CONFLICT...\n",
      "     Filtered out 201 articles. Kept 635.\n",
      "  -> Cleaning MEA_2023_GAZA_CONFLICT...\n",
      "     Filtered out 53 articles. Kept 31.\n",
      "  -> Cleaning AFR_2011_LIBYA_CONFLICT...\n",
      "     Filtered out 43 articles. Kept 26.\n",
      "  -> Cleaning MEA_2015_YEMEN_CONFLICT...\n",
      "     Filtered out 292 articles. Kept 133.\n",
      "  -> Cleaning MEA_2011_SYRIA_CONFLICT...\n",
      "     Filtered out 45 articles. Kept 35.\n",
      "  -> Cleaning EUR_2014_DONBAS_CONFLICT...\n",
      "     Filtered out 281 articles. Kept 605.\n",
      "  -> Cleaning EUR_2014_CRIMEA_CONFLICT...\n",
      "     Filtered out 20 articles. Kept 154.\n",
      "  -> Cleaning EAS_2017_KOREA_NOCONFLICT...\n",
      "     Filtered out 339 articles. Kept 285.\n",
      "  -> Cleaning MEA_2020_IRAN_NOCONFLICT...\n",
      "     Filtered out 67 articles. Kept 211.\n",
      "  -> Cleaning EUR_2021_UKRAINE_NOCONFLICT...\n",
      "     Filtered out 67 articles. Kept 90.\n",
      "  -> Cleaning SAS_2020_INDOCHINA_NOCONFLICT...\n",
      "     Filtered out 85 articles. Kept 256.\n",
      "  -> Cleaning EUR_2015_TURKEYRUSSIA_NOCONFLICT...\n",
      "     Filtered out 369 articles. Kept 273.\n",
      "  -> Cleaning SAS_2019_PULWAMA_NOCONFLICT...\n",
      "     Filtered out 117 articles. Kept 101.\n",
      "  -> Cleaning EAS_2012_SCARBOROUGH_NOCONFLICT...\n",
      "     Filtered out 26 articles. Kept 86.\n",
      "  -> Cleaning SAS_2025_PHALGAMA_NOCONFLICT...\n",
      "     Filtered out 22 articles. Kept 48.\n",
      "\n",
      "--- Data Cleaning Complete ---\n",
      "Cleaned data saved to the 'cleaned_data' folder.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "RAW_DATA_DIR = \"raw_data\"\n",
    "CLEANED_DATA_DIR = \"cleaned_data\"\n",
    "EVENTS_FILE = \"events.csv\" # Use our final events list\n",
    "#initially set to 2, trying 1\n",
    "RELEVANCE_THRESHOLD = 1 # An article must score at least 2 points to be kept\n",
    "\n",
    "def clean_and_filter():\n",
    "    \"\"\"\n",
    "    Reads raw data, scores each article for relevance, filters out noise,\n",
    "    and saves the clean data to a new directory.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(CLEANED_DATA_DIR):\n",
    "        os.makedirs(CLEANED_DATA_DIR)\n",
    "\n",
    "    events_df = pd.read_csv(EVENTS_FILE)\n",
    "    \n",
    "    print(\"--- Starting Data Cleaning and Relevance Filtering ---\")\n",
    "\n",
    "    for _, event in events_df.iterrows():\n",
    "        event_id = event['Event_ID']\n",
    "        filepath = os.path.join(RAW_DATA_DIR, f\"{event_id}.csv\")\n",
    "\n",
    "        if not os.path.exists(filepath):\n",
    "            print(f\"  -> Skipping {event_id}: Raw data file not found.\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"  -> Cleaning {event_id}...\")\n",
    "        df = pd.read_csv(filepath)\n",
    "\n",
    "        # Create a list of core, high-value keywords for this specific event\n",
    "        core_keywords = []\n",
    "        # We'll take the first 4 individuals and first 4 groups as most important\n",
    "        if pd.notna(event[\"Key_Individuals\"]):\n",
    "            core_keywords.extend([kw.strip().lower() for kw in event[\"Key_Individuals\"].split(',')[:4]])\n",
    "        if pd.notna(event[\"Key_Groups_Entities\"]):\n",
    "            core_keywords.extend([kw.strip().lower() for kw in event[\"Key_Groups_Entities\"].split(',')[:4]])\n",
    "        if pd.notna(event[\"Search_Terms\"]):\n",
    "            core_keywords.extend([kw.strip().lower() for kw in event[\"Search_Terms\"].split(',')])\n",
    "            \n",
    "        # Also include the countries as core keywords\n",
    "        core_keywords.append(event['Country_1'].lower())\n",
    "        if pd.notna(event['Country_2']):\n",
    "            core_keywords.append(event['Country_2'].lower())\n",
    "\n",
    "        # Define a function to score each article's relevance\n",
    "        def calculate_relevance(row):\n",
    "            text = (str(row['headline']) + ' ' + str(row['snippet'])).lower()\n",
    "            score = 0\n",
    "            for keyword in set(core_keywords): # Use set for efficiency\n",
    "                if keyword in text:\n",
    "                    score += 1\n",
    "            return score\n",
    "\n",
    "        df['relevance_score'] = df.apply(calculate_relevance, axis=1)\n",
    "        \n",
    "        original_count = len(df)\n",
    "        # Filter out articles that don't meet our relevance threshold\n",
    "        df_cleaned = df[df['relevance_score'] >= RELEVANCE_THRESHOLD].copy()\n",
    "        cleaned_count = len(df_cleaned)\n",
    "\n",
    "        print(f\"     Filtered out {original_count - cleaned_count} articles. Kept {cleaned_count}.\")\n",
    "\n",
    "        # Save the cleaned dataframe\n",
    "        if cleaned_count > 0:\n",
    "            cleaned_filepath = os.path.join(CLEANED_DATA_DIR, f\"{event_id}.csv\")\n",
    "            df_cleaned.to_csv(cleaned_filepath, index=False, encoding='utf-8')\n",
    "\n",
    "    print(\"\\n--- Data Cleaning Complete ---\")\n",
    "    print(f\"Cleaned data saved to the '{CLEANED_DATA_DIR}' folder.\")\n",
    "\n",
    "\n",
    "\n",
    "clean_and_filter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d538978",
   "metadata": {},
   "source": [
    "# SCARY\n",
    "\n",
    "our minimum relavance threshold and our pruninng threshhold are 2 dials we have to control the quantity and quality of data we're going to be processing. \n",
    "\n",
    "lets modify our minimum threshold function to assign differnt weights to different types of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9c7049a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Data Cleaning with WEIGHTED Relevance Filtering ---\n",
      "  -> Cleaning EUR_2022_UKRAINE_CONFLICT...\n",
      "     Filtered out 695 articles. Kept 141.\n",
      "  -> Cleaning MEA_2023_GAZA_CONFLICT...\n",
      "     Filtered out 81 articles. Kept 3.\n",
      "  -> Cleaning AFR_2011_LIBYA_CONFLICT...\n",
      "     Filtered out 68 articles. Kept 1.\n",
      "  -> Cleaning MEA_2015_YEMEN_CONFLICT...\n",
      "     Filtered out 397 articles. Kept 28.\n",
      "  -> Cleaning MEA_2011_SYRIA_CONFLICT...\n",
      "     Filtered out 79 articles. Kept 1.\n",
      "  -> Cleaning EUR_2014_DONBAS_CONFLICT...\n",
      "     Filtered out 879 articles. Kept 7.\n",
      "  -> Cleaning EUR_2014_CRIMEA_CONFLICT...\n",
      "     Filtered out 170 articles. Kept 4.\n",
      "  -> Cleaning EAS_2017_KOREA_NOCONFLICT...\n",
      "     Filtered out 623 articles. Kept 1.\n",
      "  -> Cleaning MEA_2020_IRAN_NOCONFLICT...\n",
      "     Filtered out 269 articles. Kept 9.\n",
      "  -> Cleaning EUR_2021_UKRAINE_NOCONFLICT...\n",
      "     Filtered out 151 articles. Kept 6.\n",
      "  -> Cleaning SAS_2020_INDOCHINA_NOCONFLICT...\n",
      "     Filtered out 337 articles. Kept 4.\n",
      "  -> Cleaning EUR_2015_TURKEYRUSSIA_NOCONFLICT...\n",
      "     Filtered out 639 articles. Kept 3.\n",
      "  -> Cleaning SAS_2019_PULWAMA_NOCONFLICT...\n",
      "     Filtered out 218 articles. Kept 0.\n",
      "  -> Cleaning EAS_2012_SCARBOROUGH_NOCONFLICT...\n",
      "     Filtered out 112 articles. Kept 0.\n",
      "  -> Cleaning SAS_2025_PHALGAMA_NOCONFLICT...\n",
      "     Filtered out 69 articles. Kept 1.\n",
      "\n",
      "--- Weighted Data Cleaning Complete ---\n",
      "Cleaned data saved to the 'cleaned_data' folder.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "RAW_DATA_DIR = \"raw_data\"\n",
    "CLEANED_DATA_DIR = \"cleaned_data\"\n",
    "EVENTS_FILE = \"events.csv\" # Make sure this is your latest events file\n",
    "# New threshold based on our weighted scoring system\n",
    "RELEVANCE_THRESHOLD = 3.5\n",
    "\n",
    "def clean_and_filter():\n",
    "    \"\"\"\n",
    "    Reads raw data, scores each article for relevance using a weighted system,\n",
    "    filters out noise, and saves the clean data to a new directory.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(CLEANED_DATA_DIR):\n",
    "        os.makedirs(CLEANED_DATA_DIR)\n",
    "\n",
    "    try:\n",
    "        events_df = pd.read_csv(EVENTS_FILE)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Events file '{EVENTS_FILE}' not found. Please double-check the filename.\")\n",
    "        return\n",
    "    \n",
    "    print(\"--- Starting Data Cleaning with WEIGHTED Relevance Filtering ---\")\n",
    "\n",
    "    for _, event in events_df.iterrows():\n",
    "        event_id = event['Event_ID']\n",
    "        filepath = os.path.join(RAW_DATA_DIR, f\"{event_id}.csv\")\n",
    "\n",
    "        if not os.path.exists(filepath):\n",
    "            print(f\"  -> Skipping {event_id}: Raw data file not found.\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"  -> Cleaning {event_id}...\")\n",
    "        df = pd.read_csv(filepath)\n",
    "\n",
    "        # --- Define the keyword sets for this specific event ---\n",
    "        country_keywords = set()\n",
    "        if pd.notna(event['Country_1']):\n",
    "            country_keywords.add(event['Country_1'].lower())\n",
    "        if pd.notna(event['Country_2']):\n",
    "            country_keywords.add(event['Country_2'].lower())\n",
    "\n",
    "        actor_keywords = set()\n",
    "        if pd.notna(event[\"Key_Individuals\"]):\n",
    "            actor_keywords.update([kw.strip().lower() for kw in event[\"Key_Individuals\"].split(',')])\n",
    "        if pd.notna(event[\"Key_Groups_Entities\"]):\n",
    "            actor_keywords.update([kw.strip().lower() for kw in event[\"Key_Groups_Entities\"].split(',')])\n",
    "\n",
    "        theme_keywords = set()\n",
    "        if pd.notna(event[\"Search_Terms\"]):\n",
    "            theme_keywords.update([kw.strip().lower() for kw in event[\"Search_Terms\"].split(',')])\n",
    "        \n",
    "        # --- Define the weighted scoring function ---\n",
    "        def calculate_relevance(row):\n",
    "            text = (str(row['headline']) + ' ' + str(row['snippet'])).lower()\n",
    "            \n",
    "            # Count matches for each category\n",
    "            country_matches = sum(1 for kw in country_keywords if kw in text)\n",
    "            actor_matches = sum(1 for kw in actor_keywords if kw in text)\n",
    "            theme_matches = sum(1 for kw in theme_keywords if kw in text)\n",
    "            \n",
    "            # Apply weights\n",
    "            score = (country_matches * 0.5) + (actor_matches * 2.0) + (theme_matches * 1.0)\n",
    "            return score\n",
    "\n",
    "        df['relevance_score'] = df.apply(calculate_relevance, axis=1)\n",
    "        \n",
    "        original_count = len(df)\n",
    "        # Filter out articles that don't meet our new relevance threshold\n",
    "        df_cleaned = df[df['relevance_score'] >= RELEVANCE_THRESHOLD].copy()\n",
    "        cleaned_count = len(df_cleaned)\n",
    "\n",
    "        print(f\"     Filtered out {original_count - cleaned_count} articles. Kept {cleaned_count}.\")\n",
    "\n",
    "        if cleaned_count > 0:\n",
    "            cleaned_filepath = os.path.join(CLEANED_DATA_DIR, f\"{event_id}.csv\")\n",
    "            df_cleaned.to_csv(cleaned_filepath, index=False, encoding='utf-8')\n",
    "\n",
    "    print(\"\\n--- Weighted Data Cleaning Complete ---\")\n",
    "    print(f\"Cleaned data saved to the '{CLEANED_DATA_DIR}' folder.\")\n",
    "\n",
    "clean_and_filter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cc700e",
   "metadata": {},
   "source": [
    "okay that was too aggressive, how about we just look for articles that mention country AND have atleast 1 key actor or event/group mentioned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f906347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Data Cleaning with SIMPLIFIED 'Country & Actor' Rule ---\n",
      "  -> Cleaning EUR_2022_UKRAINE_CONFLICT...\n",
      "     Filtered out 467 articles. Kept 369.\n",
      "  -> Cleaning MEA_2023_GAZA_CONFLICT...\n",
      "     Filtered out 74 articles. Kept 10.\n",
      "  -> Cleaning AFR_2011_LIBYA_CONFLICT...\n",
      "     Filtered out 57 articles. Kept 12.\n",
      "  -> Cleaning MEA_2015_YEMEN_CONFLICT...\n",
      "     Filtered out 386 articles. Kept 39.\n",
      "  -> Cleaning MEA_2011_SYRIA_CONFLICT...\n",
      "     Filtered out 75 articles. Kept 5.\n",
      "  -> Cleaning EUR_2014_DONBAS_CONFLICT...\n",
      "     Filtered out 789 articles. Kept 97.\n",
      "  -> Cleaning EUR_2014_CRIMEA_CONFLICT...\n",
      "     Filtered out 117 articles. Kept 57.\n",
      "  -> Cleaning EAS_2017_KOREA_NOCONFLICT...\n",
      "     Filtered out 592 articles. Kept 32.\n",
      "  -> Cleaning MEA_2020_IRAN_NOCONFLICT...\n",
      "     Filtered out 200 articles. Kept 78.\n",
      "  -> Cleaning EUR_2021_UKRAINE_NOCONFLICT...\n",
      "     Filtered out 125 articles. Kept 32.\n",
      "  -> Cleaning SAS_2020_INDOCHINA_NOCONFLICT...\n",
      "     Filtered out 270 articles. Kept 71.\n",
      "  -> Cleaning EUR_2015_TURKEYRUSSIA_NOCONFLICT...\n",
      "     Filtered out 593 articles. Kept 49.\n",
      "  -> Cleaning SAS_2019_PULWAMA_NOCONFLICT...\n",
      "     Filtered out 207 articles. Kept 11.\n",
      "  -> Cleaning EAS_2012_SCARBOROUGH_NOCONFLICT...\n",
      "     Filtered out 108 articles. Kept 4.\n",
      "  -> Cleaning SAS_2025_PHALGAMA_NOCONFLICT...\n",
      "     Filtered out 54 articles. Kept 16.\n",
      "\n",
      "--- Simplified Data Cleaning Complete ---\n",
      "Cleaned data saved to the 'cleaned_data' folder.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "RAW_DATA_DIR = \"raw_data\"\n",
    "CLEANED_DATA_DIR = \"cleaned_data\"\n",
    "EVENTS_FILE = \"events.csv\" # Make sure this is your latest events file\n",
    "\n",
    "def clean_and_filter_simple():\n",
    "    \"\"\"\n",
    "    Reads raw data, keeps articles based on a simple \"Country AND Actor\" rule,\n",
    "    and saves the results to a new directory. This is a more robust method.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(CLEANED_DATA_DIR):\n",
    "        os.makedirs(CLEANED_DATA_DIR)\n",
    "\n",
    "    try:\n",
    "        events_df = pd.read_csv(EVENTS_FILE)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Events file '{EVENTS_FILE}' not found. Please double-check the filename.\")\n",
    "        return\n",
    "    \n",
    "    print(\"--- Starting Data Cleaning with SIMPLIFIED 'Country & Actor' Rule ---\")\n",
    "\n",
    "    for _, event in events_df.iterrows():\n",
    "        event_id = event['Event_ID']\n",
    "        filepath = os.path.join(RAW_DATA_DIR, f\"{event_id}.csv\")\n",
    "\n",
    "        if not os.path.exists(filepath):\n",
    "            print(f\"  -> Skipping {event_id}: Raw data file not found.\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"  -> Cleaning {event_id}...\")\n",
    "        df = pd.read_csv(filepath)\n",
    "\n",
    "        # --- Define the keyword sets for this specific event ---\n",
    "        country_keywords = set()\n",
    "        if pd.notna(event['Country_1']):\n",
    "            country_keywords.add(event['Country_1'].lower())\n",
    "        if pd.notna(event['Country_2']):\n",
    "            country_keywords.add(event['Country_2'].lower())\n",
    "\n",
    "        actor_keywords = set()\n",
    "        if pd.notna(event[\"Key_Individuals\"]):\n",
    "            actor_keywords.update([kw.strip().lower() for kw in event[\"Key_Individuals\"].split(',')])\n",
    "        if pd.notna(event[\"Key_Groups_Entities\"]):\n",
    "            actor_keywords.update([kw.strip().lower() for kw in event[\"Key_Groups_Entities\"].split(',')])\n",
    "\n",
    "        # Define the simple filtering function\n",
    "        def is_relevant(row):\n",
    "            text = (str(row['headline']) + ' ' + str(row['snippet'])).lower()\n",
    "            \n",
    "            # Check for at least one country and at least one actor\n",
    "            has_country = any(kw in text for kw in country_keywords)\n",
    "            has_actor = any(kw in text for kw in actor_keywords)\n",
    "            \n",
    "            return has_country and has_actor\n",
    "\n",
    "        # Apply the filter\n",
    "        df_cleaned = df[df.apply(is_relevant, axis=1)].copy()\n",
    "        \n",
    "        original_count = len(df)\n",
    "        cleaned_count = len(df_cleaned)\n",
    "\n",
    "        print(f\"     Filtered out {original_count - cleaned_count} articles. Kept {cleaned_count}.\")\n",
    "\n",
    "        if cleaned_count > 0:\n",
    "            cleaned_filepath = os.path.join(CLEANED_DATA_DIR, f\"{event_id}.csv\")\n",
    "            df_cleaned.to_csv(cleaned_filepath, index=False, encoding='utf-8')\n",
    "\n",
    "    print(\"\\n--- Simplified Data Cleaning Complete ---\")\n",
    "    print(f\"Cleaned data saved to the '{CLEANED_DATA_DIR}' folder.\")\n",
    "\n",
    "clean_and_filter_simple()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f4765f",
   "metadata": {},
   "source": [
    "Still too agressive, A better approach would be to just assign the relavance score to each article, and move on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe5fc13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Full Feature Engineering (with Capping) ---\n",
      "  -> Processing EUR_2022_UKRAINE_CONFLICT...\n",
      "     Event has 836 articles. Capping to 500 via random sample.\n",
      "  -> Processing MEA_2023_GAZA_CONFLICT...\n",
      "  -> Processing AFR_2011_LIBYA_CONFLICT...\n",
      "  -> Processing MEA_2015_YEMEN_CONFLICT...\n",
      "  -> Processing MEA_2011_SYRIA_CONFLICT...\n",
      "  -> Processing EUR_2014_DONBAS_CONFLICT...\n",
      "     Event has 886 articles. Capping to 500 via random sample.\n",
      "  -> Processing EUR_2014_CRIMEA_CONFLICT...\n",
      "  -> Processing EAS_2017_KOREA_NOCONFLICT...\n",
      "     Event has 624 articles. Capping to 500 via random sample.\n",
      "  -> Processing MEA_2020_IRAN_NOCONFLICT...\n",
      "  -> Processing EUR_2021_UKRAINE_NOCONFLICT...\n",
      "  -> Processing SAS_2020_INDOCHINA_NOCONFLICT...\n",
      "  -> Processing EUR_2015_TURKEYRUSSIA_NOCONFLICT...\n",
      "     Event has 642 articles. Capping to 500 via random sample.\n",
      "  -> Processing SAS_2019_PULWAMA_NOCONFLICT...\n",
      "  -> Processing EAS_2012_SCARBOROUGH_NOCONFLICT...\n",
      "  -> Processing SAS_2025_PHALGAMA_NOCONFLICT...\n",
      "\n",
      "--- Feature Engineering Complete ---\n"
     ]
    }
   ],
   "source": [
    "# FINAL feature_engineering.py with Capping\n",
    "import os\n",
    "import pandas as pd\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "RAW_DATA_DIR = \"raw_data\"\n",
    "FEATURES_DIR = \"features\"\n",
    "EVENTS_FILE = \"events.csv\"\n",
    "ARTICLE_CAP = 500  # The maximum number of articles to use from any single event\n",
    "RANDOM_STATE = 42 # For reproducible random sampling\n",
    "\n",
    "# Keyword definitions remain the same\n",
    "RHETORICAL_KEYWORD_TIERS = {\n",
    "    1: ['tensions', 'dispute', 'protest', 'unrest', 'sanctions', 'diplomat', 'condemn', 'concern', 'warns'],\n",
    "    3: ['threat', 'mobilize', 'mobilization', 'mobilizing', 'drill', 'exercise', 'border', 'violation', 'standoff', 'brink'],\n",
    "    5: ['ultimatum', 'attack', 'airstrike', 'invasion', 'casualties', 'clashes', 'imminent', 'offensive', 'shelling']\n",
    "}\n",
    "CERTAINTY_KEYWORDS = {\n",
    "    1: ['will', 'confirms', 'is', 'fact', 'order', 'declares', 'announces', 'instructs', 'guarantees', 'unquestionably'],\n",
    "   -1: ['could', 'may', 'might', 'suggests', 'appears', 'reportedly', 'seems', 'potential', 'unconfirmed', 'possibly', 'perhaps']\n",
    "}\n",
    "\n",
    "def create_all_features():\n",
    "    if not os.path.exists(FEATURES_DIR):\n",
    "        os.makedirs(FEATURES_DIR)\n",
    "\n",
    "    events_df = pd.read_csv(EVENTS_FILE)\n",
    "    sentiment_analyzer = SentimentIntensityAnalyzer()\n",
    "    \n",
    "    print(\"--- Starting Full Feature Engineering (with Capping) ---\")\n",
    "\n",
    "    for _, event in events_df.iterrows():\n",
    "        event_id = event['Event_ID']\n",
    "        filepath = os.path.join(RAW_DATA_DIR, f\"{event_id}.csv\")\n",
    "\n",
    "        if not os.path.exists(filepath):\n",
    "            continue\n",
    "            \n",
    "        print(f\"  -> Processing {event_id}...\")\n",
    "        df = pd.read_csv(filepath)\n",
    "        \n",
    "        # --- NEW CAPPING LOGIC ---\n",
    "        if len(df) > ARTICLE_CAP:\n",
    "            print(f\"     Event has {len(df)} articles. Capping to {ARTICLE_CAP} via random sample.\")\n",
    "            df = df.sample(n=ARTICLE_CAP, random_state=RANDOM_STATE)\n",
    "        # -------------------------\n",
    "\n",
    "        df['text_to_analyze'] = df['headline'].fillna('') + ' ' + df['snippet'].fillna('')\n",
    "\n",
    "        country_keywords = {kw.lower() for kw in [event['Country_1'], event['Country_2']] if pd.notna(kw)}\n",
    "        actor_keywords = set()\n",
    "        if pd.notna(event[\"Key_Individuals\"]):\n",
    "            actor_keywords.update([kw.strip().lower() for kw in event[\"Key_Individuals\"].split(',')])\n",
    "        if pd.notna(event[\"Key_Groups_Entities\"]):\n",
    "            actor_keywords.update([kw.strip().lower() for kw in event[\"Key_Groups_Entities\"].split(',')])\n",
    "\n",
    "        def process_row(text):\n",
    "            lower_text = text.lower()\n",
    "            sentiment = sentiment_analyzer.polarity_scores(text)['compound']\n",
    "            rhetoric = sum(p for p, kws in RHETORICAL_KEYWORD_TIERS.items() for kw in kws if kw in lower_text)\n",
    "            certainty = sum(p for p, kws in CERTAINTY_KEYWORDS.items() for kw in kws if kw in lower_text.split())\n",
    "            relevance = sum(1 for kw in country_keywords if kw in lower_text) + sum(1 for kw in actor_keywords if kw in lower_text)\n",
    "            return sentiment, rhetoric, certainty, relevance\n",
    "\n",
    "        df[['sentiment_compound', 'rhetoric_score', 'certainty_score', 'relevance_score']] = df['text_to_analyze'].apply(\n",
    "            lambda x: pd.Series(process_row(x))\n",
    "        )\n",
    "        \n",
    "        df = df.drop(columns=['text_to_analyze'])\n",
    "        features_filepath = os.path.join(FEATURES_DIR, f\"{event_id}.csv\")\n",
    "        df.to_csv(features_filepath, index=False, encoding='utf-8')\n",
    "\n",
    "    print(\"\\n--- Feature Engineering Complete ---\")\n",
    "\n",
    "\n",
    "create_all_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9e4745",
   "metadata": {},
   "source": [
    "Sweet, now we can use relevance as a metric  too\n",
    "\n",
    "now we aggregrate these features again and proceed to modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56965f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score\n",
    "\n",
    "MODEL_FILE = 'final_model_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93725c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data prepared. Using 15 features.\n",
      "Dataset has 177 total weekly observations.\n",
      "Conflict cases: 82 | No Conflict cases: 95\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df = pd.read_csv(MODEL_FILE)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Model data file '{MODEL_FILE}' not found. Please run aggregate_features.py first.\")\n",
    "    \n",
    "\n",
    "# Handle potential missing values (e.g., in '_std' columns for weeks with 1 article)\n",
    "# We will fill these with 0 for simplicity.\n",
    "df = df.fillna(0)\n",
    "\n",
    "# --- 2. Feature Engineering & Selection ---\n",
    "# Our goal is to predict the 'Outcome' based on the weekly features.\n",
    "\n",
    "# Convert the 'Outcome' column to a binary format (0 or 1)\n",
    "df['Outcome_binary'] = df['Outcome'].apply(lambda x: 1 if x == 'Conflict' else 0)\n",
    "\n",
    "# The features for our model are all the numerical columns we created\n",
    "# We exclude identifiers like Event_ID and the original Outcome string\n",
    "features = [col for col in df.columns if col not in ['Event_ID', 'Outcome', 'Outcome_binary']]\n",
    "\n",
    "X = df[features]\n",
    "y = df['Outcome_binary']\n",
    "\n",
    "print(f\"Data prepared. Using {len(X.columns)} features.\")\n",
    "print(f\"Dataset has {len(df)} total weekly observations.\")\n",
    "print(f\"Conflict cases: {y.sum()} | No Conflict cases: {len(y) - y.sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "022446e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week_before_event</th>\n",
       "      <th>article_count</th>\n",
       "      <th>certainty_score_mean</th>\n",
       "      <th>certainty_score_sum</th>\n",
       "      <th>relevance_score_max</th>\n",
       "      <th>relevance_score_mean</th>\n",
       "      <th>relevance_score_min</th>\n",
       "      <th>relevance_score_std</th>\n",
       "      <th>rhetoric_score_max</th>\n",
       "      <th>rhetoric_score_mean</th>\n",
       "      <th>rhetoric_score_sum</th>\n",
       "      <th>sentiment_compound_max</th>\n",
       "      <th>sentiment_compound_mean</th>\n",
       "      <th>sentiment_compound_min</th>\n",
       "      <th>sentiment_compound_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-12</td>\n",
       "      <td>11</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.539360</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.6576</td>\n",
       "      <td>-0.294145</td>\n",
       "      <td>-0.9475</td>\n",
       "      <td>0.644075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-11</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.2732</td>\n",
       "      <td>-0.187175</td>\n",
       "      <td>-0.7096</td>\n",
       "      <td>0.503790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-0.8126</td>\n",
       "      <td>-0.892450</td>\n",
       "      <td>-0.9723</td>\n",
       "      <td>0.112925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.4588</td>\n",
       "      <td>-0.653450</td>\n",
       "      <td>-0.8481</td>\n",
       "      <td>0.275277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-8</td>\n",
       "      <td>11</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.674200</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.7959</td>\n",
       "      <td>-0.610555</td>\n",
       "      <td>-0.9800</td>\n",
       "      <td>0.648782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>-5</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.9300</td>\n",
       "      <td>-0.930000</td>\n",
       "      <td>-0.9300</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>-4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.8271</td>\n",
       "      <td>-0.209500</td>\n",
       "      <td>-0.8979</td>\n",
       "      <td>0.811816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>-3</td>\n",
       "      <td>8</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.353553</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.4939</td>\n",
       "      <td>-0.243787</td>\n",
       "      <td>-0.9100</td>\n",
       "      <td>0.520639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>-2</td>\n",
       "      <td>12</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.797724</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.083333</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.8271</td>\n",
       "      <td>-0.562625</td>\n",
       "      <td>-0.9643</td>\n",
       "      <td>0.589446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7579</td>\n",
       "      <td>0.271900</td>\n",
       "      <td>-0.5106</td>\n",
       "      <td>0.684257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>177 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     week_before_event  article_count  certainty_score_mean  \\\n",
       "0                  -12             11              0.272727   \n",
       "1                  -11              4              0.000000   \n",
       "2                  -10              2              0.500000   \n",
       "3                   -9              2              0.500000   \n",
       "4                   -8             11              0.545455   \n",
       "..                 ...            ...                   ...   \n",
       "172                 -5              1             -1.000000   \n",
       "173                 -4              4              0.750000   \n",
       "174                 -3              8              0.750000   \n",
       "175                 -2             12              0.333333   \n",
       "176                 -1              3              0.333333   \n",
       "\n",
       "     certainty_score_sum  relevance_score_max  relevance_score_mean  \\\n",
       "0                    3.0                  2.0              0.909091   \n",
       "1                    0.0                  1.0              0.250000   \n",
       "2                    1.0                  1.0              1.000000   \n",
       "3                    1.0                  0.0              0.000000   \n",
       "4                    6.0                  2.0              0.363636   \n",
       "..                   ...                  ...                   ...   \n",
       "172                 -1.0                  0.0              0.000000   \n",
       "173                  3.0                  0.0              0.000000   \n",
       "174                  6.0                  1.0              0.125000   \n",
       "175                  4.0                  2.0              0.500000   \n",
       "176                  1.0                  1.0              0.333333   \n",
       "\n",
       "     relevance_score_min  relevance_score_std  rhetoric_score_max  \\\n",
       "0                    0.0             0.539360                 5.0   \n",
       "1                    0.0             0.500000                 5.0   \n",
       "2                    1.0             0.000000                 8.0   \n",
       "3                    0.0             0.000000                 1.0   \n",
       "4                    0.0             0.674200                 4.0   \n",
       "..                   ...                  ...                 ...   \n",
       "172                  0.0             0.000000                 0.0   \n",
       "173                  0.0             0.000000                10.0   \n",
       "174                  0.0             0.353553                 4.0   \n",
       "175                  0.0             0.797724                 7.0   \n",
       "176                  0.0             0.577350                 1.0   \n",
       "\n",
       "     rhetoric_score_mean  rhetoric_score_sum  sentiment_compound_max  \\\n",
       "0               0.818182                 9.0                  0.6576   \n",
       "1               3.000000                12.0                  0.2732   \n",
       "2               4.000000                 8.0                 -0.8126   \n",
       "3               0.500000                 1.0                 -0.4588   \n",
       "4               0.727273                 8.0                  0.7959   \n",
       "..                   ...                 ...                     ...   \n",
       "172             0.000000                 0.0                 -0.9300   \n",
       "173             2.500000                10.0                  0.8271   \n",
       "174             0.875000                 7.0                  0.4939   \n",
       "175             3.083333                37.0                  0.8271   \n",
       "176             0.333333                 1.0                  0.7579   \n",
       "\n",
       "     sentiment_compound_mean  sentiment_compound_min  sentiment_compound_std  \n",
       "0                  -0.294145                 -0.9475                0.644075  \n",
       "1                  -0.187175                 -0.7096                0.503790  \n",
       "2                  -0.892450                 -0.9723                0.112925  \n",
       "3                  -0.653450                 -0.8481                0.275277  \n",
       "4                  -0.610555                 -0.9800                0.648782  \n",
       "..                       ...                     ...                     ...  \n",
       "172                -0.930000                 -0.9300                0.000000  \n",
       "173                -0.209500                 -0.8979                0.811816  \n",
       "174                -0.243787                 -0.9100                0.520639  \n",
       "175                -0.562625                 -0.9643                0.589446  \n",
       "176                 0.271900                 -0.5106                0.684257  \n",
       "\n",
       "[177 rows x 15 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64773642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      1\n",
       "2      1\n",
       "3      1\n",
       "4      1\n",
       "      ..\n",
       "172    1\n",
       "173    1\n",
       "174    1\n",
       "175    1\n",
       "176    1\n",
       "Name: Outcome_binary, Length: 177, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e9e8c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training complete.\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "model = LogisticRegression(class_weight='balanced', max_iter=10000, random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "print(\"Model training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "75b2f4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Model Performance ---\n",
      "Model Accuracy on Test Set: 0.5278\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Evaluating Model Performance ---\")\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy on Test Set: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29b66e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "[[12  7]\n",
      " [10  7]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " No Conflict       0.55      0.63      0.59        19\n",
      "    Conflict       0.50      0.41      0.45        17\n",
      "\n",
      "    accuracy                           0.53        36\n",
      "   macro avg       0.52      0.52      0.52        36\n",
      "weighted avg       0.52      0.53      0.52        36\n",
      "\n",
      "\n",
      "--- Model Interpretation: Most Important Features ---\n",
      "Top 10 features predicting 'Conflict' (Positive Coefficients):\n",
      "                    Feature  Coefficient  Abs_Coefficient\n",
      "4       relevance_score_max     0.537597         0.537597\n",
      "7       relevance_score_std     0.466362         0.466362\n",
      "2      certainty_score_mean     0.374857         0.374857\n",
      "1             article_count     0.362494         0.362494\n",
      "10       rhetoric_score_sum     0.338286         0.338286\n",
      "13   sentiment_compound_min     0.282554         0.282554\n",
      "14   sentiment_compound_std     0.233462         0.233462\n",
      "6       relevance_score_min     0.219595         0.219595\n",
      "12  sentiment_compound_mean     0.162990         0.162990\n",
      "8        rhetoric_score_max     0.111213         0.111213\n",
      "\n",
      "Top 10 features predicting 'No Conflict' (Negative Coefficients):\n",
      "                   Feature  Coefficient  Abs_Coefficient\n",
      "11  sentiment_compound_max    -1.010274         1.010274\n",
      "3      certainty_score_sum    -0.487332         0.487332\n",
      "5     relevance_score_mean    -0.312543         0.312543\n",
      "0        week_before_event    -0.133758         0.133758\n",
      "9      rhetoric_score_mean    -0.097811         0.097811\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nConfusion Matrix:\")\n",
    "# A confusion matrix shows us what the model got right and what it got wrong.\n",
    "# [[True Negative, False Positive], [False Negative, True Positive]]\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['No Conflict', 'Conflict']))\n",
    "import numpy as np\n",
    "# --- 7. Interpret the Model - Find the \"Tipping Point\" ---\n",
    "print(\"\\n--- Model Interpretation: Most Important Features ---\")\n",
    "\n",
    "# Get the coefficients (the \"importance\" score) the model learned for each feature\n",
    "coefficients = model.coef_[0]\n",
    "\n",
    "# Create a DataFrame to view the features and their learned importance\n",
    "feature_importance = pd.DataFrame({'Feature': features, 'Coefficient': coefficients})\n",
    "\n",
    "# Sort by the absolute value of the coefficient to see the most impactful features\n",
    "feature_importance['Abs_Coefficient'] = np.abs(feature_importance['Coefficient'])\n",
    "feature_importance = feature_importance.sort_values(by='Abs_Coefficient', ascending=False)\n",
    "\n",
    "print(\"Top 10 features predicting 'Conflict' (Positive Coefficients):\")\n",
    "print(feature_importance[feature_importance['Coefficient'] > 0].head(10))\n",
    "\n",
    "print(\"\\nTop 10 features predicting 'No Conflict' (Negative Coefficients):\")\n",
    "print(feature_importance[feature_importance['Coefficient'] < 0].head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7525a47",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "\n",
    "we notice that the model is slightly better at predicting when coflict doesn't occur (referencing the higher recall score (.63) for No conflict), versus when conflict does occur (referencing the low recall score (.41) for conflict). This goes to indicate that the model is cautious in nature- potentially reflecting the nature of the singular news source we're conducting our study on. Aditionally, we see that precision for both conflict and no conflict is marignally better than tossing a coin, showing that the model is from a researcher's point of view, doing as much as tossing a coin. While this was disappointing to take in, it showcases a powerful truth: News reports aren't magical crystal orbs. They are purely meant to inform and entertain. World politics is an infinitley complex system, and the onset of war is a decision that has hundreds of hands on the steering wheel.\n",
    "\n",
    "# FEATURE IMPORTANCE\n",
    "\n",
    "coming to decoding how our model decided what it decided, we see a compelling reason as to why it was far more conservative in it's prediction. The one feature that the model deemed was most important when considering if war would break out was the relevence score max, followed by relevence score std. This finding is interesting, because it hints at the fact that as we head towards a conflict, news simultaneously becomes more chaotic and extreme. Nonetheless, it was pretty bad at confirming the outcome. \n",
    "On the other hand, the sentiment compound max shows an absolute coefficint of 1.01 This means that the model found that high positive sentiment was a strong indicator of no conflict. It far surpassed any other feature on it's sheer ability to confirm the outcome. \n",
    "\n",
    "This presents yet another important truth: positive news has a much greater ability to confirm a stable future than negative news has to confirm a grim one. I find this beautiful. In a world where negativity pervades all around us, it is refreshing to see that focusing on the positive side of things can give as alot more hope than we otherwise would allow. \n",
    "\n",
    "# Visualisations v2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "69a896bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating Final Story Visualizations ---\n",
      "-> Saved visual_3_final_confusion_matrix.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v8/1wyl6_ks02s620m7tv5drmch0000gn/T/ipykernel_94179/3997530344.py:43: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x='Coefficient', y='Feature', data=features_df, palette=colors, orient='h')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Saved visual_4_final_feature_importance.png\n",
      "-> Saved visual_5_final_tipping_point.png\n",
      "\n",
      "--- Final visualizations are ready! ---\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# --- Configuration & Final Model Results ---\n",
    "MODEL_DATA_FILE = \"final_model_data.csv\"\n",
    "CONFUSION_MATRIX_VALUES = [[12, 7], [10, 7]] # From your final results\n",
    "FEATURE_COEFFICIENTS = {\n",
    "    'relevance_score_max': 0.538, 'relevance_score_std': 0.466,\n",
    "    'certainty_score_mean': 0.375, 'article_count': 0.362,\n",
    "    'rhetoric_score_sum': 0.338, 'sentiment_compound_min': 0.283,\n",
    "    'sentiment_compound_std': 0.233, 'relevance_score_min': 0.220,\n",
    "    'sentiment_compound_mean': 0.163, 'rhetoric_score_max': 0.111,\n",
    "    'sentiment_compound_max': -1.010, 'certainty_score_sum': -0.487,\n",
    "    'relevance_score_mean': -0.313, 'week_before_event': -0.134,\n",
    "    'rhetoric_score_mean': -0.098\n",
    "}\n",
    "\n",
    "def create_final_visuals():\n",
    "    \"\"\"Generates and saves the final visualizations for the project story.\"\"\"\n",
    "    print(\"--- Generating Final Story Visualizations ---\")\n",
    "    sns.set_theme(style=\"darkgrid\", font_scale=1.1)\n",
    "\n",
    "    # --- Visual #3: The Model's Scorecard (Confusion Matrix) ---\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    ax = sns.heatmap(CONFUSION_MATRIX_VALUES, annot=True, fmt='g', cmap='viridis', cbar=False)\n",
    "    ax.set_title(\"The Model's Scorecard (Accuracy: 53%)\", fontsize=16, pad=20)\n",
    "    ax.set_xlabel('Predicted Outcome', labelpad=15)\n",
    "    ax.set_ylabel('Actual Outcome', labelpad=15)\n",
    "    ax.xaxis.set_ticklabels(['No Conflict', 'Conflict'])\n",
    "    ax.yaxis.set_ticklabels(['No Conflict', 'Conflict'])\n",
    "    plt.savefig('visual_3_final_confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"-> Saved visual_3_final_confusion_matrix.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # --- Visual #4: The Decisive Signals (Feature Importance) ---\n",
    "    features_df = pd.DataFrame(FEATURE_COEFFICIENTS.items(), columns=['Feature', 'Coefficient'])\n",
    "    features_df['Abs_Coefficient'] = features_df['Coefficient'].abs()\n",
    "    features_df = features_df.sort_values(by='Abs_Coefficient', ascending=False)\n",
    "    colors = ['#2ca02c' if c < 0 else '#d62728' for c in features_df['Coefficient']]\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(x='Coefficient', y='Feature', data=features_df, palette=colors, orient='h')\n",
    "    plt.title('The Decisive Signals: What Predicts Peace vs. Conflict?', fontsize=18, pad=20)\n",
    "    plt.xlabel('Coefficient (Pull Towards \"Conflict\" vs. \"No Conflict\")', labelpad=15)\n",
    "    plt.ylabel('Rhetorical Feature', labelpad=15)\n",
    "    plt.axvline(0, color='black', linewidth=0.8)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('visual_4_final_feature_importance.png', dpi=300)\n",
    "    print(\"-> Saved visual_4_final_feature_importance.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # --- Visual #5: The \"Chaos & Hope\" Time-Series Plot ---\n",
    "    try:\n",
    "        df = pd.read_csv(MODEL_DATA_FILE)\n",
    "        # Using Ukraine 2022 (Conflict) and Turkey/Russia 2015 (a high-stakes No Conflict case)\n",
    "        conflict_event = df[df['Event_ID'] == 'EUR_2022_UKRAINE_CONFLICT']\n",
    "        no_conflict_event = df[df['Event_ID'] == 'EUR_2015_TURKEYRUSSIA_NOCONFLICT']\n",
    "        \n",
    "        fig, ax1 = plt.subplots(figsize=(14, 8))\n",
    "        \n",
    "        # Plot 1: The \"Hope\" Metric (Max Sentiment)\n",
    "        sns.lineplot(x='week_before_event', y='sentiment_compound_max', data=conflict_event, \n",
    "                     label='Hope Signal (Ukraine 2022 - Conflict)', color='#1f77b4', marker='o', ax=ax1)\n",
    "        sns.lineplot(x='week_before_event', y='sentiment_compound_max', data=no_conflict_event, \n",
    "                     label='Hope Signal (Turkey/Russia 2015 - No Conflict)', color='#2ca02c', marker='o', ax=ax1)\n",
    "        ax1.set_ylabel('Max Sentiment Score (Presence of Hope)', labelpad=15)\n",
    "        ax1.set_ylim(-1.05, 1.05) # Lock y-axis for sentiment\n",
    "\n",
    "        # Plot 2: The \"Chaos\" Metric (Relevance Volatility)\n",
    "        ax2 = ax1.twinx()\n",
    "        sns.lineplot(x='week_before_event', y='relevance_score_std', data=conflict_event, \n",
    "                     label='Chaos Signal (Ukraine 2022)', color='#d62728', linestyle='--', marker='x', ax=ax2)\n",
    "        sns.lineplot(x='week_before_event', y='relevance_score_std', data=no_conflict_event, \n",
    "                     label='Chaos Signal (Turkey/Russia 2015)', color='#ff7f0e', linestyle='--', marker='x', ax=ax2)\n",
    "        ax2.set_ylabel('Std. Dev. of Relevance Score (Information Chaos)', labelpad=15)\n",
    "        \n",
    "        fig.suptitle('The Tipping Point: The Disappearance of Hope Amidst Chaos', fontsize=18)\n",
    "        ax1.set_xlabel('Weeks Before Peak Tension / Invasion', labelpad=15)\n",
    "        ax1.set_xticks(range(-12, 0, 1))\n",
    "        \n",
    "        # Combine legends\n",
    "        lines, labels = ax1.get_legend_handles_labels()\n",
    "        lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "        ax2.legend(lines + lines2, labels + labels2, loc='upper left')\n",
    "        ax1.get_legend().remove()\n",
    "        \n",
    "        plt.savefig('visual_5_final_tipping_point.png', dpi=300, bbox_inches='tight')\n",
    "        print(\"-> Saved visual_5_final_tipping_point.png\")\n",
    "        plt.close()\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"-> Skipped Visual #5: Could not find '{MODEL_DATA_FILE}'.\")\n",
    "        \n",
    "    print(\"\\n--- Final visualizations are ready! ---\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_final_visuals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "16a01be6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            EUR_2022_UKRAINE_CONFLICT\n",
       "1               MEA_2023_GAZA_CONFLICT\n",
       "2              AFR_2011_LIBYA_CONFLICT\n",
       "3              MEA_2015_YEMEN_CONFLICT\n",
       "4              MEA_2011_SYRIA_CONFLICT\n",
       "5             EUR_2014_DONBAS_CONFLICT\n",
       "6             EUR_2014_CRIMEA_CONFLICT\n",
       "7            EAS_2017_KOREA_NOCONFLICT\n",
       "8             MEA_2020_IRAN_NOCONFLICT\n",
       "9          EUR_2021_UKRAINE_NOCONFLICT\n",
       "10       SAS_2020_INDOCHINA_NOCONFLICT\n",
       "11    EUR_2015_TURKEYRUSSIA_NOCONFLICT\n",
       "12         SAS_2019_PULWAMA_NOCONFLICT\n",
       "13     EAS_2012_SCARBOROUGH_NOCONFLICT\n",
       "14        SAS_2025_PHALGAMA_NOCONFLICT\n",
       "Name: Event_ID, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"events.csv\")['Event_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "31d4b9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Preparing Final Data for Mapping ---\n",
      "-> Successfully created 'map_data.csv'. You can now upload this to a mapping tool.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- Configuration ---\n",
    "# Make sure this points to your final, pruned events file\n",
    "EVENTS_FILE = \"events.csv\"\n",
    "MAP_DATA_OUTPUT_FILE = \"map_data.csv\"\n",
    "\n",
    "# This dictionary now matches your final list of 15 events exactly.\n",
    "location_data = {\n",
    "    'EUR_2022_UKRAINE_CONFLICT': (48.3, 31.1, \"Ukraine Invasion (2022)\"),\n",
    "    'MEA_2023_GAZA_CONFLICT': (31.5, 34.4, \"Gaza Conflict (2023)\"),\n",
    "    'AFR_2011_LIBYA_CONFLICT': (26.3, 17.2, \"Libyan Civil War (2011)\"),\n",
    "    'MEA_2015_YEMEN_CONFLICT': (15.5, 48.5, \"Yemen Intervention (2015)\"),\n",
    "    'MEA_2011_SYRIA_CONFLICT': (35.0, 38.0, \"Syrian Civil War (2011)\"),\n",
    "    'EUR_2014_DONBAS_CONFLICT': (48.0, 37.8, \"Donbas War (2014)\"),\n",
    "    'EUR_2014_CRIMEA_CONFLICT': (45.3, 34.3, \"Crimea Annexation (2014)\"),\n",
    "    'EAS_2017_KOREA_NOCONFLICT': (38.7, 127.5, \"Korean Peninsula Crisis (2017)\"),\n",
    "    'MEA_2020_IRAN_NOCONFLICT': (32.4, 53.6, \"Iran-US Crisis (2020)\"),\n",
    "    'EUR_2021_UKRAINE_NOCONFLICT': (48.3, 31.1, \"Ukraine Buildup (2021)\"),\n",
    "    'SAS_2020_INDOCHINA_NOCONFLICT': (34.1, 78.7, \"India-China Standoff (2020)\"),\n",
    "    'EUR_2015_TURKEYRUSSIA_NOCONFLICT': (36.8, 36.6, \"Turkey-Russia Jet Crisis (2015)\"),\n",
    "    'SAS_2019_PULWAMA_NOCONFLICT': (34.0, 74.4, \"India-Pakistan Crisis (2019)\"),\n",
    "    'EAS_2012_SCARBOROUGH_NOCONFLICT': (15.1, 117.8, \"Scarborough Shoal Standoff (2012)\"),\n",
    "    'SAS_2025_PHALGAMA_NOCONFLICT': (34.0, 74.4, \"Kashmir Crisis (2025)\")\n",
    "}\n",
    "\n",
    "def create_map_data():\n",
    "    \"\"\"Prepares the data needed for an online mapping tool using the final event list.\"\"\"\n",
    "    print(\"--- Preparing Final Data for Mapping ---\")\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(EVENTS_FILE)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Could not find '{EVENTS_FILE}'. Please ensure the filename is correct.\")\n",
    "        return\n",
    "\n",
    "    # Filter the dataframe to only include the events we have location data for\n",
    "    df = df[df['Event_ID'].isin(location_data.keys())].copy()\n",
    "\n",
    "    # Map the location data to the dataframe\n",
    "    df['latitude'] = df['Event_ID'].map(lambda x: location_data[x][0])\n",
    "    df['longitude'] = df['Event_ID'].map(lambda x: location_data[x][1])\n",
    "    df['location_name'] = df['Event_ID'].map(lambda x: location_data[x][2])\n",
    "\n",
    "    # Select and save only the necessary columns\n",
    "    map_df = df[['latitude', 'longitude', 'location_name', 'Outcome']]\n",
    "    map_df.to_csv(MAP_DATA_OUTPUT_FILE, index=False)\n",
    "    \n",
    "    print(f\"-> Successfully created '{MAP_DATA_OUTPUT_FILE}'. You can now upload this to a mapping tool.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_map_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9c7a0e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_articles = 0\n",
    "\n",
    "for dir_name,dirs,files in os.walk(\"raw_data\"):\n",
    "    for file in files:\n",
    "        total_articles += pd.read_csv(\"raw_data/\"+file).shape[0]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f5bcedd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4996"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "960770ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "capped_articles = 0\n",
    "for dir_name,dirs,files in os.walk(\"processed_data\"):\n",
    "    for file in files:\n",
    "        capped_articles += pd.read_csv(\"processed_data/\"+file).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bb86dccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4008"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "capped_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "22a66a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggegrated_data = pd.read_csv(\"final_model_data.csv\").shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6b2d72fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggegrated_data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "518bc3b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating Styled Table Images ---\n",
      "-> Saved table_1_confusion_matrix.png\n",
      "-> Saved table_2_classification_report.png\n",
      "-> Saved table_3_feature_importance.png\n",
      "\n",
      "--- All table images generated successfully! ---\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def render_df_to_image(df, title, filename, col_widths=[1.5, 1, 1, 1]):\n",
    "    \"\"\"\n",
    "    Renders a pandas DataFrame as a high-quality image with a title.\n",
    "    \"\"\"\n",
    "    # Create a figure and axis object\n",
    "    fig, ax = plt.subplots(figsize=(8, 4))  # Adjust size as needed\n",
    "    ax.axis('off')  # Hide the axes\n",
    "    ax.set_title(title, fontweight=\"bold\", pad=20, fontsize=16)\n",
    "\n",
    "    # Create the table and add it to the axis\n",
    "    table = ax.table(\n",
    "        cellText=df.values,\n",
    "        colLabels=df.columns,\n",
    "        cellLoc='center',\n",
    "        loc='center',\n",
    "        colWidths=col_widths\n",
    "    )\n",
    "\n",
    "    # Style the table\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(12)\n",
    "    table.scale(1.2, 1.2)\n",
    "\n",
    "    # Style the header\n",
    "    for (i, j), cell in table.get_celld().items():\n",
    "        if i == 0:  # Header row\n",
    "            cell.set_text_props(weight='bold', color='white')\n",
    "            cell.set_facecolor('#40466e')\n",
    "        else: # Data rows\n",
    "            cell.set_facecolor('#f2f2f2')\n",
    "\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight', pad_inches=0.5)\n",
    "    print(f\"-> Saved {filename}\")\n",
    "    plt.close()\n",
    "\n",
    "def create_styled_table_images():\n",
    "    \"\"\"\n",
    "    Creates and saves styled images for all the final result tables.\n",
    "    \"\"\"\n",
    "    print(\"--- Generating Styled Table Images ---\")\n",
    "\n",
    "    # --- Table 1: Confusion Matrix ---\n",
    "    cm_data = [[12, 7], [10, 7]]\n",
    "    cm_df = pd.DataFrame(cm_data,\n",
    "                         columns=['Predicted: No Conflict', 'Predicted: Conflict'],\n",
    "                         index=['Actual: No Conflict', 'Actual: Conflict'])\n",
    "    # Custom rendering for confusion matrix colors\n",
    "    fig, ax = plt.subplots(figsize=(6, 4))\n",
    "    ax.axis('off')\n",
    "    ax.set_title(\"Model Performance Scorecard (Accuracy: 53%)\", fontweight=\"bold\", pad=20, fontsize=16)\n",
    "    table = ax.table(cellText=cm_df.values, colLabels=cm_df.columns, rowLabels=cm_df.index, cellLoc='center', loc='center')\n",
    "    table.scale(1.2, 1.5)\n",
    "    table.set_fontsize(14)\n",
    "    # Color the cells\n",
    "    table.get_celld()[(1, 0)].set_facecolor('#d62728') # True Pos\n",
    "    table.get_celld()[(1, 0)].set_text_props(color='white')\n",
    "    table.get_celld()[(0, 1)].set_facecolor('#ff7f0e') # False Pos\n",
    "    table.get_celld()[(1, -1)].set_facecolor('#d62728') # Row Header\n",
    "    table.get_celld()[(1, -1)].set_text_props(weight='bold')\n",
    "    table.get_celld()[(2, -1)].set_facecolor('#ff7f0e') # Row Header\n",
    "    table.get_celld()[(2, -1)].set_text_props(weight='bold')\n",
    "    table.get_celld()[(2, 0)].set_facecolor('#ff7f0e') # False Neg\n",
    "    table.get_celld()[(2, 1)].set_facecolor('#2ca02c') # True Pos\n",
    "    table.get_celld()[(2, 1)].set_text_props(color='white')\n",
    "    table.get_celld()[(0, 0)].set_facecolor('#2ca02c') # True Neg\n",
    "    table.get_celld()[(0, 0)].set_text_props(color='white')\n",
    "    plt.savefig('table_1_confusion_matrix.png', dpi=300, bbox_inches='tight', pad_inches=0.5)\n",
    "    print(\"-> Saved table_1_confusion_matrix.png\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    # --- Table 2: Classification Report ---\n",
    "    report_data = {\n",
    "        'Class': ['No Conflict', 'Conflict'],\n",
    "        'Precision': [0.55, 0.50],\n",
    "        'Recall': [0.63, 0.41],\n",
    "        'F1-Score': [0.59, 0.45]\n",
    "    }\n",
    "    report_df = pd.DataFrame(report_data).set_index('Class')\n",
    "    render_df_to_image(report_df.reset_index(), \"Detailed Performance Metrics\", \"table_2_classification_report.png\")\n",
    "\n",
    "    # --- Table 3: Feature Importance ---\n",
    "    feature_data = {\n",
    "        'Signal': ['For Peace (-)', 'For Conflict (+)', 'For Peace (-)', 'For Conflict (+)', 'For Conflict (+)', 'For Conflict (+)', 'For Conflict (+)', 'For Peace (-)', 'For Conflict (+)', 'For Conflict (+)', 'For Conflict (+)', 'For Conflict (+)', 'For Peace (-)', 'For Conflict (+)', 'For Peace (-)'],\n",
    "        'Feature': ['sentiment_compound_max', 'relevance_score_max', 'certainty_score_sum', 'relevance_score_std', 'certainty_score_mean', 'article_count', 'rhetoric_score_sum', 'relevance_score_mean', 'sentiment_compound_min', 'sentiment_compound_std', 'relevance_score_min', 'sentiment_compound_mean', 'week_before_event', 'rhetoric_score_max', 'rhetoric_score_mean'],\n",
    "        'Coefficient': [-1.01, 0.54, -0.49, 0.47, 0.37, 0.36, 0.34, -0.31, 0.28, 0.23, 0.22, 0.16, -0.13, 0.11, -0.10]\n",
    "    }\n",
    "    importance_df = pd.DataFrame(feature_data)\n",
    "    # Custom rendering for feature importance table\n",
    "    fig, ax = plt.subplots(figsize=(8, 9))\n",
    "    ax.axis('off')\n",
    "    ax.set_title(\"Key Predictive Features (The Model's 'Brain')\", fontweight=\"bold\", pad=20, fontsize=16)\n",
    "    table = ax.table(cellText=importance_df.values, colLabels=importance_df.columns, cellLoc='left', loc='center', colWidths=[0.3, 0.5, 0.2])\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(11)\n",
    "    table.scale(1.2, 1.2)\n",
    "    # Color rows based on signal\n",
    "    for i in range(len(importance_df) + 1):\n",
    "        if i == 0: # Header\n",
    "             for j in range(3):\n",
    "                table.get_celld()[(i, j)].set_text_props(weight='bold', color='white')\n",
    "                table.get_celld()[(i, j)].set_facecolor('#40466e')\n",
    "        else: # Data rows\n",
    "            signal = table.get_celld()[(i, 0)].get_text().get_text()\n",
    "            color = '#dff0d8' if 'Peace' in signal else '#f2dede'\n",
    "            for j in range(3):\n",
    "                table.get_celld()[(i, j)].set_facecolor(color)\n",
    "    plt.savefig('table_3_feature_importance.png', dpi=300, bbox_inches='tight', pad_inches=0.5)\n",
    "    print(\"-> Saved table_3_feature_importance.png\")\n",
    "    plt.close()\n",
    "\n",
    "    print(\"\\n--- All table images generated successfully! ---\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_styled_table_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7070c1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Preparing Final Jittered Data for Mapping ---\n",
      "-> Successfully created 'map_data.csv'. You can now upload this to your mapping tool.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- Configuration ---\n",
    "# Make sure this points to your final, pruned events file\n",
    "EVENTS_FILE = \"events.csv\" \n",
    "MAP_DATA_OUTPUT_FILE = \"map_data.csv\"\n",
    "\n",
    "# This dictionary now has \"jittered\" coordinates for the overlapping events.\n",
    "location_data = {\n",
    "    # Ukraine Conflict is centered\n",
    "    'EUR_2022_UKRAINE_CONFLICT': (48.3, 31.1, \"Ukraine Invasion (2022)\"),\n",
    "    # Ukraine Buildup is slightly offset to appear as a separate dot\n",
    "    'EUR_2021_UKRAINE_NOCONFLICT': (49.0, 32.5, \"Ukraine Buildup (2021)\"),\n",
    "\n",
    "    'MEA_2023_GAZA_CONFLICT': (31.5, 34.4, \"Gaza Conflict (2023)\"),\n",
    "    'AFR_2011_LIBYA_CONFLICT': (26.3, 17.2, \"Libyan Civil War (2011)\"),\n",
    "    'MEA_2015_YEMEN_CONFLICT': (15.5, 48.5, \"Yemen Intervention (2015)\"),\n",
    "    'MEA_2011_SYRIA_CONFLICT': (35.0, 38.0, \"Syrian Civil War (2011)\"),\n",
    "    'EUR_2014_DONBAS_CONFLICT': (48.0, 37.8, \"Donbas War (2014)\"),\n",
    "    'EUR_2014_CRIMEA_CONFLICT': (45.3, 34.3, \"Crimea Annexation (2014)\"),\n",
    "    'EAS_2017_KOREA_NOCONFLICT': (38.7, 127.5, \"Korean Peninsula Crisis (2017)\"),\n",
    "    'MEA_2020_IRAN_NOCONFLICT': (32.4, 53.6, \"Iran-US Crisis (2020)\"),\n",
    "    'SAS_2020_INDOCHINA_NOCONFLICT': (34.1, 78.7, \"India-China Standoff (2020)\"),\n",
    "    'EUR_2015_TURKEYRUSSIA_NOCONFLICT': (36.8, 36.6, \"Turkey-Russia Jet Crisis (2015)\"),\n",
    "    \n",
    "    # Pulwama Crisis is centered on Kashmir\n",
    "    'SAS_2019_PULWAMA_NOCONFLICT': (34.0, 74.4, \"India-Pakistan Crisis (2019)\"),\n",
    "    # Phalgam Crisis is slightly offset\n",
    "    'SAS_2025_PHALGAMA_NOCONFLICT': (34.5, 75.0, \"Kashmir Crisis (2025)\"),\n",
    "\n",
    "    'EAS_2012_SCARBOROUGH_NOCONFLICT': (15.1, 117.8, \"Scarborough Shoal Standoff (2012)\")\n",
    "}\n",
    "\n",
    "\n",
    "def create_map_data():\n",
    "    \"\"\"Prepares the data needed for an online mapping tool with corrected coordinates.\"\"\"\n",
    "    print(\"--- Preparing Final Jittered Data for Mapping ---\")\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(EVENTS_FILE)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Could not find '{EVENTS_FILE}'. Please ensure the filename is correct.\")\n",
    "        return\n",
    "\n",
    "    # Filter the dataframe to only include the events we have location data for\n",
    "    df_filtered = df[df['Event_ID'].isin(location_data.keys())].copy()\n",
    "\n",
    "    if len(df_filtered) != 15:\n",
    "         print(f\"Warning: Your events file has {len(df_filtered)} matching events, but expected 15. Please check your events.gold.v2.csv file.\")\n",
    "\n",
    "\n",
    "    # Map the location data to the dataframe\n",
    "    df_filtered['latitude'] = df_filtered['Event_ID'].map(lambda x: location_data[x][0])\n",
    "    df_filtered['longitude'] = df_filtered['Event_ID'].map(lambda x: location_data[x][1])\n",
    "    df_filtered['location_name'] = df_filtered['Event_ID'].map(lambda x: location_data[x][2])\n",
    "\n",
    "    # Select and save only the necessary columns\n",
    "    map_df = df_filtered[['latitude', 'longitude', 'location_name', 'Outcome']]\n",
    "    map_df.to_csv(MAP_DATA_OUTPUT_FILE, index=False)\n",
    "    \n",
    "    print(f\"-> Successfully created '{MAP_DATA_OUTPUT_FILE}'. You can now upload this to your mapping tool.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_map_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2289f0ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
